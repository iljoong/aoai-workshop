{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3ce09c-2b1f-4912-af44-33b4592e67a2",
   "metadata": {},
   "source": [
    "# Vector Search - Query\n",
    "\n",
    "> Use index create by built-in index feature\n",
    "\n",
    "Azure AI Search:\n",
    "- Vector Search\n",
    "- Hybrid Search\n",
    "- Semantic Search\n",
    "\n",
    "https://github.com/Azure/azure-search-vector-samples/blob/main/demo-python/readme.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f420f0-4270-4a1d-933b-6aa974e4482b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ea588-8536-4a74-bdfd-feafbdc6520d",
   "metadata": {},
   "source": [
    "> update value of `index_name` to your index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6a4f87-683b-4dcb-88da-622599dd6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "# Variables not used here do not need to be updated in your .env file\n",
    "endpoint = os.environ[\"AZSCH_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.environ[\"AZSCH_KEY\"])\n",
    "\n",
    "index_name = os.environ[\"AZSCH_INDEX_NAME\"]\n",
    "\n",
    "#azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "#azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"] if len(os.environ[\"AZURE_OPENAI_KEY\"]) > 0 else None\n",
    "#azure_openai_embedding_deployment = os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0f4503-d440-45c3-9be0-b1804ca810a3",
   "metadata": {},
   "source": [
    "## Search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a253351b-e463-4d6a-83a6-4e40a2ce2fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is OpenAI assistant api?\"  \n",
    "topK = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2a31757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5475f0a",
   "metadata": {},
   "source": [
    "## Text Search\n",
    "\n",
    "- vector_queries = None\n",
    "- search_text = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cfd713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 11.026696, Title: What is Azure OpenAI Service?, chunk_id: 0\n",
      "   parent_id: overview.md\n",
      "Score: 9.364173, Title: What is Azure OpenAI Service?, chunk_id: 1\n",
      "   parent_id: overview.md\n",
      "Score: 9.149903, Title: Azure OpenAI Service Assistant API concepts, chunk_id: 0\n",
      "   parent_id: assistants.md\n"
     ]
    }
   ],
   "source": [
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "  \n",
    "# Text Search\n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries=None,\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\", \"title\"],\n",
    "    top=topK\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}, Title: {result['title']}, chunk_id: {result['chunk_id'][-1]}\") \n",
    "    print(f\"   parent_id: {result['parent_id']}\")  \n",
    "    #print(f\"Content: {result['chunk']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093138f8-4a3e-47e3-b3e8-a550b94feade",
   "metadata": {},
   "source": [
    "## Vector Search\n",
    "\n",
    "> Add __vector profile__ manually in the index\n",
    "\n",
    "- vector_queries = [vector_query]\n",
    "- search_text = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ddafb0-1c74-4c9b-8450-317576bda94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.879656, Title: Azure OpenAI Service Assistant API concepts, chunk_id: 0\n",
      "   parent_id: assistants.md\n",
      "Score: 0.86666685, Title: How to create Assistants with Azure OpenAI Service, chunk_id: 0\n",
      "   parent_id: assistant.md\n",
      "Score: 0.86589706, Title: Quickstart - Getting started with Azure OpenAI Assistants (Preview), chunk_id: 0\n",
      "   parent_id: assistants-quickstart.md\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "# Pure Vector Search\n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=topK, fields=\"vector\", exhaustive=True)\n",
    "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
    "#vector_query = RawVectorQuery(vector=generate_embeddings(query), k_nearest_neighbors=3, fields=\"vector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\", \"title\"],\n",
    "    top=topK\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}, Title: {result['title']}, chunk_id: {result['chunk_id'][-1]}\") \n",
    "    print(f\"   parent_id: {result['parent_id']}\")  \n",
    "    #print(f\"Content: {result['chunk']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc702e94-604d-4169-80ce-a74c333a5c3e",
   "metadata": {},
   "source": [
    "## Hybrid Search\n",
    "\n",
    "- vector_queries = [vector query]\n",
    "- search_text = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f7322a7-ee47-422d-92bf-ad8c8fc42801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.03279569745063782, Title: Azure OpenAI Service Assistant API concepts, chunk_id: 0\n",
      "   parent_id: assistants.md\n",
      "Score: 0.024205941706895828, Title: How to create Assistants with Azure OpenAI Service, chunk_id: 0\n",
      "   parent_id: assistant.md\n",
      "Score: 0.019187135621905327, Title: Quickstart - Getting started with Azure OpenAI Assistants (Preview), chunk_id: 0\n",
      "   parent_id: assistants-quickstart.md\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Search\n",
    "#search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=topK, fields=\"vector\", exhaustive=True)\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\", \"title\"],\n",
    "    top=topK\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}, Title: {result['title']}, chunk_id: {result['chunk_id'][-1]}\") \n",
    "    print(f\"   parent_id: {result['parent_id']}\")  \n",
    "    #print(f\"Content: {result['chunk']}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dbb322-e511-44a7-a283-4df80e31e497",
   "metadata": {},
   "source": [
    "## Semantic Search (Hybrid search + semantic reranking)\n",
    "\n",
    "> Add __semantic configuration__ manually in the index and update the value of `semantic_configuration_name` parameter.\n",
    "\n",
    "- vector_queries = [vector_query]\n",
    "- search_text = query\n",
    "- query_type=QueryType.SEMANTIC,\n",
    "- semantic_configuration_name='your-semantic-config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5167dbf-5b9d-4ab9-85b1-58a050542066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.03279569745063782, Title: Azure OpenAI Service Assistant API concepts, chunk_id: 0\n",
      "   Reranker Score: 3.357616901397705\n",
      "   parent_id: assistants.md\n",
      "   >Caption: # Azure OpenAI Assistants API (Preview)  Assistants, a new feature of Azure OpenAI Service, is now available in public preview. While the chat completions API is lightwei... The Assistants<em> API, as </em>the<em> stateful evolution of the chat completion API, provides a solution for these challenges.</em> Assistants API supports persistent automatically managed.\n",
      "\n",
      "Score: 0.024205941706895828, Title: How to create Assistants with Azure OpenAI Service, chunk_id: 0\n",
      "   Reranker Score: 3.00740122795105\n",
      "   parent_id: assistant.md\n",
      "   >Caption: # Getting started with Azure OpenAI Assistants (Preview)  Azure OpenAI Assistants (Preview) allows you to create<em> AI </em>assistants tailored to your needs through<em> custom instructions and augmented by advanced tools like code interpreter, and custom functions.</em> In this article we'll provide an in-depth walkthrough of getting started with the Assistants.\n",
      "\n",
      "Score: 0.01315789483487606, Title: How to work with the Chat Completion API , chunk_id: 3\n",
      "   Reranker Score: 2.9258735179901123\n",
      "   parent_id: chat-completion.md\n",
      "   >Caption: ``` {\"role\": \"system\", \"content\": \"Assistant is an<em> intelligent chatbot designed to help users answer technical questions about Azure OpenAI Serivce.</em> Context: - Azure OpenAI Service provides REST API access to OpenAI's powerful language models including the GPT-3, Codex and Embeddings model series. - Azure OpenAI Service gives customers advanced.\n",
      "\n",
      "Semantic Answers:\n",
      "   >Semantic Answer: # Quickstart: Get started using Azure<em> OpenAI </em>Assistants (Preview)  Azure<em> OpenAI </em>Assistants (Preview) allows you to<em> create AI assistants tailored to </em>your<em> needs through custom instructions and augmented by advanced tools like code interpreter, and custom functions. </em> ::: zone pivot=\"programming-language-studio\"  [!INCLUDE [Studio quickstart](includ...\n",
      "   >Semantic Answer Score: 0.972000002861023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    QueryCaptionType,\n",
    "    QueryAnswerType\n",
    ")\n",
    "\n",
    "# Semantic search\n",
    "#search_client = SearchClient(endpoint, index_name, credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=topK, fields=\"vector\", exhaustive=True)\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\", \"title\"],\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name='semantic-config',\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=topK\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Score: {result['@search.score']}, Title: {result['title']}, chunk_id: {result['chunk_id'][-1]}\") \n",
    "    print(f\"   Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"   parent_id: {result['parent_id']}\")  \n",
    "    #print(f\"Content: {result['chunk']}\")  \n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"   >Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"   >Caption: {caption.text}\\n\")\n",
    "\n",
    "print(\"Semantic Answers:\")\n",
    "semantic_answers = results.get_answers()\n",
    "if semantic_answers:\n",
    "    for answer in semantic_answers:\n",
    "        if answer.highlights:\n",
    "            print(f\"   >Semantic Answer: {answer.highlights}\")\n",
    "        else:\n",
    "            print(f\"   >Semantic Answer: {answer.text}\")\n",
    "        print(f\"   >Semantic Answer Score: {answer.score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1320a2-223c-4c21-a3ab-2f4cca69da7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
