{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3ce09c-2b1f-4912-af44-33b4592e67a2",
   "metadata": {},
   "source": [
    "# Vector Search - Query\n",
    "\n",
    "> Use index create by built-in index feature\n",
    "\n",
    "Azure AI Search:\n",
    "- Vector Search\n",
    "- Hybrid Search\n",
    "- Semantic Search\n",
    "\n",
    "https://github.com/Azure/azure-search-vector-samples/blob/main/demo-python/readme.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f420f0-4270-4a1d-933b-6aa974e4482b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ea588-8536-4a74-bdfd-feafbdc6520d",
   "metadata": {},
   "source": [
    "> update value of `index_name` to your index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da6a4f87-683b-4dcb-88da-622599dd6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "# Variables not used here do not need to be updated in your .env file\n",
    "endpoint = os.environ[\"AZSCH_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.environ[\"AZSCH_KEY\"])\n",
    "\n",
    "index_name = 'aoai-docs-idx'\n",
    "\n",
    "#azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "#azure_openai_key = os.environ[\"AZURE_OPENAI_KEY\"] if len(os.environ[\"AZURE_OPENAI_KEY\"]) > 0 else None\n",
    "#azure_openai_embedding_deployment = os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0f4503-d440-45c3-9be0-b1804ca810a3",
   "metadata": {},
   "source": [
    "## Search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a253351b-e463-4d6a-83a6-4e40a2ce2fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is OpenAI assistant api?\"  \n",
    "topK = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a31757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5475f0a",
   "metadata": {},
   "source": [
    "## Text Search\n",
    "\n",
    "- vector_queries = None\n",
    "- search_text = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cfd713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 6.859043, Title: assistants-studio.md, chunk_id: 2\n",
      "   parent_id: aHR0cHM6Ly9pa2Jsb2JhY2N0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2NzL2Fzc2lzdGFudHMtc3R1ZGlvLm1k0\n",
      "Score: 6.7678576, Title: assistant-functions.md, chunk_id: 0\n",
      "   parent_id: aHR0cHM6Ly9pa2Jsb2JhY2N0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2NzL2Fzc2lzdGFudC1mdW5jdGlvbnMubWQ1\n",
      "Score: 6.609729, Title: prompt-chat-completion.md, chunk_id: 0\n",
      "   parent_id: aHR0cHM6Ly9pa2Jsb2JhY2N0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2NzL3Byb21wdC1jaGF0LWNvbXBsZXRpb24ubWQ1\n"
     ]
    }
   ],
   "source": [
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "  \n",
    "# Text Search\n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries=None,\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\", \"title\"],\n",
    "    top=topK\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}, Title: {result['title']}, chunk_id: {result['chunk_id'][-1]}\") \n",
    "    print(f\"   parent_id: {result['parent_id']}\")  \n",
    "    #print(f\"Content: {result['chunk']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093138f8-4a3e-47e3-b3e8-a550b94feade",
   "metadata": {},
   "source": [
    "## Vector Search\n",
    "\n",
    "- vector_queries = [vector_query]\n",
    "- search_text = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ddafb0-1c74-4c9b-8450-317576bda94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8802705, Title: assistants.md, chunk_id: 0\n",
      "   parent_id: aHR0cHM6Ly9pa2Jsb2JhY2N0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2NzL2Fzc2lzdGFudHMubWQ1\n",
      "Score: 0.86489004, Title: chatgpt-studio.md, chunk_id: 1\n",
      "   parent_id: aHR0cHM6Ly9pa2Jsb2JhY2N0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2NzL2NoYXRncHQtc3R1ZGlvLm1k0\n",
      "Score: 0.86298484, Title: chat-markup-language.md, chunk_id: 5\n",
      "   parent_id: aHR0cHM6Ly9pa2Jsb2JhY2N0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2NzL2NoYXQtbWFya3VwLWxhbmd1YWdlLm1k0\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "# Pure Vector Search\n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=topK, fields=\"vector\", exhaustive=True)\n",
    "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
    "# vector_query = RawVectorQuery(vector=generate_embeddings(query), k_nearest_neighbors=3, fields=\"vector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\", \"title\"],\n",
    "    top=topK\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}, Title: {result['title']}, chunk_id: {result['chunk_id'][-1]}\") \n",
    "    print(f\"   parent_id: {result['parent_id']}\")  \n",
    "    #print(f\"Content: {result['chunk']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc702e94-604d-4169-80ce-a74c333a5c3e",
   "metadata": {},
   "source": [
    "## Hybrid Search\n",
    "\n",
    "- vector_queries = [vector query]\n",
    "- search_text = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f7322a7-ee47-422d-92bf-ad8c8fc42801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.02982766181230545, Title: chat-markup-language.md, chunk_id: 5\n",
      "   parent_id: aHR0cHM6Ly9pa2Jsb2JhY2N0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2NzL2NoYXQtbWFya3VwLWxhbmd1YWdlLm1k0\n",
      "Score: 0.02708333358168602, Title: assistants.md, chunk_id: 0\n",
      "   parent_id: aHR0cHM6Ly9pa2Jsb2JhY2N0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2NzL2Fzc2lzdGFudHMubWQ1\n",
      "Score: 0.02194899693131447, Title: chatgpt-studio.md, chunk_id: 1\n",
      "   parent_id: aHR0cHM6Ly9pa2Jsb2JhY2N0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2NzL2NoYXRncHQtc3R1ZGlvLm1k0\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Search\n",
    "#search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=topK, fields=\"vector\", exhaustive=True)\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\", \"title\"],\n",
    "    top=topK\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}, Title: {result['title']}, chunk_id: {result['chunk_id'][-1]}\") \n",
    "    print(f\"   parent_id: {result['parent_id']}\")  \n",
    "    #print(f\"Content: {result['chunk']}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dbb322-e511-44a7-a283-4df80e31e497",
   "metadata": {},
   "source": [
    "## Semantic Search (Hybrid search + semantic reranking)\n",
    "\n",
    "- vector_queries = [vector_query]\n",
    "- search_text = query\n",
    "- query_type=QueryType.SEMANTIC,\n",
    "- semantic_configuration_name='your-semantic-config'\n",
    "\n",
    "> Update the value of `semantic_configuration_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5167dbf-5b9d-4ab9-85b1-58a050542066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.02708333358168602, Title: assistants.md, chunk_id: 0\n",
      "   Reranker Score: 3.403339385986328\n",
      "   parent_id: aHR0cHM6Ly9pa2Jsb2JhY2N0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2NzL2Fzc2lzdGFudHMubWQ1\n",
      "   >Caption: <em>Assistants API</em> makes it easier for developers to create applications with sophisticated copilot-like experiences that can sift through data, suggest solutions, and automate tasks. ## Overview  Previously, building custom<em> AI assistants</em> needed heavy lifting even for experienced developers.\n",
      "\n",
      "Score: 0.012500000186264515, Title: assistants-reference.md, chunk_id: 0\n",
      "   Reranker Score: 3.0249693393707275\n",
      "   parent_id: aHR0cHM6Ly9pa2Jsb2JhY2N0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2NzL2Fzc2lzdGFudHMtcmVmZXJlbmNlLm1k0\n",
      "   >Caption: assistants-reference.md. --- title: azure<em> openai</em> service<em> assistants</em> python & rest<em> api</em> reference titlesuffix: azure<em> openai</em> description: learn how to use azure<em> openai's</em> python & rest<em> api</em> with assistants. manager: nitinme ms.service: azure-ai-openai ms.topic: conceptual ms.date: 02/07/2024 author: mrbullwinkle ms.author: mbullwin recommendations: â€¦\n",
      "\n",
      "Score: 0.015384615398943424, Title: completions.md, chunk_id: 8\n",
      "   Reranker Score: 2.9299938678741455\n",
      "   parent_id: aHR0cHM6Ly9pa2Jsb2JhY2N0LmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2NzL2NvbXBsZXRpb25zLm1k0\n",
      "   >Caption: The key is to tell the<em> API</em> how it should behave and then provide a few examples. In this demonstration, the<em> API</em> supplies the role of an<em> AI</em> answering questions:  ```console The following is a conversation with an<em> AI assistant.</em> The assistant is helpful, creative, clever, and very friendly. Human: Hello, who are you? AI: I am an<em> AI</em> created by<em> OpenAI.</em>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    QueryCaptionType,\n",
    "    QueryAnswerType\n",
    ")\n",
    "\n",
    "# Semantic search\n",
    "#search_client = SearchClient(endpoint, index_name, credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=topK, fields=\"vector\", exhaustive=True)\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\", \"title\"],\n",
    "    query_type=QueryType.SEMANTIC,\n",
    "    semantic_configuration_name='aoai-docs-idx-semantic-configuration',\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=topK\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Score: {result['@search.score']}, Title: {result['title']}, chunk_id: {result['chunk_id'][-1]}\") \n",
    "    print(f\"   Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"   parent_id: {result['parent_id']}\")  \n",
    "    #print(f\"Content: {result['chunk']}\")  \n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"   >Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"   >Caption: {caption.text}\\n\")\n",
    "            \n",
    "semantic_answers = results.get_answers()\n",
    "if semantic_answers:\n",
    "    for answer in semantic_answers:\n",
    "        if answer.highlights:\n",
    "            print(f\"   >Semantic Answer: {answer.highlights}\")\n",
    "        else:\n",
    "            print(f\"   >Semantic Answer: {answer.text}\")\n",
    "        print(f\"   >Semantic Answer Score: {answer.score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1320a2-223c-4c21-a3ab-2f4cca69da7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
