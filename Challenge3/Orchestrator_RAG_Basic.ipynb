{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3ce09c-2b1f-4912-af44-33b4592e67a2",
   "metadata": {},
   "source": [
    "# AI Orchestrator - RAG Basic\n",
    "\n",
    "user query -> search -> generate answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885ee653-e41c-4a48-85c2-9edb52161179",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f420f0-4270-4a1d-933b-6aa974e4482b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2dec4-b4c0-4fee-a38b-fa5366830c81",
   "metadata": {},
   "source": [
    "> update the name of environment variables(`AZURE_OPENAI_KEY`, `AZURE_OPENAI_ENDPOINT`) and the value of `index_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39fc3e81-86dc-4d1a-b9a7-f2691d706fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "#MODEL = \"gpt-4o\"\n",
    "MODEL = \"gpt-35-turbo\"\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.environ['AZURE_OPENAI_KEY'],\n",
    "    #api_version=\"2024-10-01-preview\",\n",
    "    api_version=\"2024-08-01-preview\",\n",
    "    azure_endpoint = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abbe964c-729d-4dd4-b3b3-de2fcc312e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _chat_gpt(messages, model=MODEL, temp=0, topp=0.1):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temp,\n",
    "        max_tokens=2000,\n",
    "        top_p=topp\n",
    "    )   \n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da6a4f87-683b-4dcb-88da-622599dd6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "# Variables not used here do not need to be updated in your .env file\n",
    "endpoint = os.environ[\"AZSCH_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.environ[\"AZSCH_KEY\"])\n",
    "\n",
    "index_name = os.environ[\"AZSCH_INDEX_NAME\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0f4503-d440-45c3-9be0-b1804ca810a3",
   "metadata": {},
   "source": [
    "## Search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a253351b-e463-4d6a-83a6-4e40a2ce2fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is OpenAI assistant api?\"  \n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093138f8-4a3e-47e3-b3e8-a550b94feade",
   "metadata": {},
   "source": [
    "## Search\n",
    "\n",
    "Vector Search\n",
    "- vectorquery = \"query\"\n",
    "- search_text = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22ddafb0-1c74-4c9b-8450-317576bda94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_id: assistants-python.md\n",
      "  chunk_id: 0\n",
      "  Score: 0.85328734\n",
      "parent_id: assistant.md\n",
      "  chunk_id: 0\n",
      "  Score: 0.8505703\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "topK = 2\n",
    "\n",
    "# Pure Vector Search\n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=topK, fields=\"vector\", exhaustive=True)\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
    "    top=topK\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"parent_id: {result['parent_id']}\")  \n",
    "    print(f\"  chunk_id: {result['chunk_id']}\")  \n",
    "    print(f\"  Score: {result['@search.score']}\")  \n",
    "    #print(f\"Content: {result['chunk']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3151cca2-1e1a-4e84-a6cc-8ce7b3ef26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(text):\n",
    "    vector_query = VectorizableTextQuery(text=text, k_nearest_neighbors=topK, fields=\"vector\", exhaustive=True)\n",
    "    results = search_client.search(  \n",
    "        search_text=None,  \n",
    "        vector_queries= [vector_query],\n",
    "        select=[\"parent_id\", \"chunk_id\", \"chunk\", \"title\"],\n",
    "        top=topK\n",
    "    )  \n",
    "\n",
    "    context = \"\"\n",
    "    metadata = []\n",
    "    for result in results:  \n",
    "        context = context + result['chunk'] + \"\\n\\n\"\n",
    "        metadata.append({\"score\": result['@search.score'], \"chunk_id\": result['chunk_id'], \"parent_id\": result['parent_id'], \"title\": result[\"title\"]})\n",
    "\n",
    "    return context, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5b1d98a-8e36-4958-be7a-505cd2ffb093",
   "metadata": {},
   "outputs": [],
   "source": [
    "context, metadata = get_context(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a65f8f-c28e-4af3-8940-08f7d34c6343",
   "metadata": {},
   "source": [
    "## Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dc02f5b-a1da-44c8-b445-9937ff6daff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt templates\n",
    "from jinja2 import Template\n",
    "from common import parse_chat\n",
    "\n",
    "with open('./reply_simple.jinja2') as file:\n",
    "    simple_response_template = file.read()\n",
    "\n",
    "with open('./reply_simple_ground.jinja2') as file:\n",
    "    ground_response_template = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "184bfbda-8339-4e83-9406-f0ac043ce1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system:\n",
      "You are a helpful and friendly assistant. Generate answer based on the context provided below. \n",
      "If you user asked in Korean then answer back in Korean otherwise answer in English only.\n",
      "\n",
      "## Context\n",
      "<a href=\"https://github.com/openai/openai-python\" target=\"_blank\">Library source code</a> | <a href=\"https://pypi.org/project/openai/\" target=\"_blank\">Package (PyPi)</a> |\n",
      "\n",
      "## Prerequisites\n",
      "\n",
      "- An Azure subscription - <a href=\"https://azure.microsoft.com/free/cognitive-services\" target=\"_blank\">Create one for free</a>\n",
      "- Access granted to Azure OpenAI in the desired Azure subscription\n",
      "\n",
      "    Currently, access to this service is granted only by application. You can apply for access to Azure OpenAI by completing the form at <a href=\"https://aka.ms/oai/access\" target=\"_blank\">https://aka.ms/oai/access</a>. Open an issue on this repo to contact us if you have an issue.\n",
      "- <a href=\"https://www.python.org/\" target=\"_blank\">Python 3.7.1 or later version</a>\n",
      "- The following Python libraries: os, json, openai (Version 1.x is required)\n",
      "- [Jupyter Notebooks](https://jupyter.org/)\n",
      "- Azure OpenAI Assistants are currently available in Sweden Central, East US 2, and Australia East. For more information about model availability in those regions, see the [models guide](../concepts/models.md).\n",
      "- We recommend reviewing the [Responsible AI transparency note](/legal/cognitive-services/openai/transparency-note?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext&tabs=text) and other [Responsible AI resources](/legal/cognitive-services/openai/overview?context=%2Fazure%2Fai-services%2Fopenai%2Fcontext%2Fcontext) to familiarize yourself with the capabilities and limitations of the Azure OpenAI Service.\n",
      "- An Azure OpenAI resource with the `gpt-4 (1106-preview)` model deployed was used testing this example.\n",
      "\n",
      "## Set up\n",
      "\n",
      "Install the OpenAI Python client library with:\n",
      "\n",
      "```console\n",
      "pip install openai\n",
      "```\n",
      "\n",
      "> [!NOTE]\n",
      "> This library is maintained by OpenAI. Refer to the [release history](https://github.com/openai/openai-python/releases) to track the latest updates to the library.\n",
      "\n",
      "## Retrieve key and endpoint\n",
      "\n",
      "To successfully make a call against the Azure OpenAI service, you'll need the following:\n",
      "\n",
      "|Variable name | Value |\n",
      "|--------------------------|-------------|\n",
      "| `ENDPOINT`               | This value can be found in the **Keys and Endpoint** section when examining your resource from the Azure portal. Alternatively, you can find the value in **Azure OpenAI Studio** > **Playground** > **View code**. An example endpoint is: `https://docs-test-001.openai.azure.com/`.|\n",
      "| `API-KEY` | This value can be found in the **Keys and Endpoint** section when examining your resource from the Azure portal. You can use either `KEY1` or `KEY2`.|\n",
      "| `DEPLOYMENT-NAME` | This value will correspond to the custom name you chose for your deployment when you deployed a model. This value can be found under **Resource Management** > **Model Deployments** in the Azure portal or alternatively under **Management** > **Deployments** in Azure OpenAI Studio.|\n",
      "\n",
      "Go to your resource in the Azure portal. The **Keys and Endpoint** can be found in the **Resource Management** section. Copy your endpoint and access key as you'll need both for authenticating your API calls. You can use either `KEY1` or `KEY2`. Always having two keys allows you to securely rotate and regenerate keys without causing a service disruption.\n",
      "\n",
      ":::image type=\"content\" source=\"../media/quickstarts/endpoint.png\" alt-text=\"Screenshot of the overview blade for an OpenAI Resource in the Azure portal with the endpoint & access keys location circled in red.\" lightbox=\"../media/quickstarts/endpoint.png\":::\n",
      "\n",
      "Create and assign persistent environment variables for your key and endpoint.\n",
      "\n",
      "[!INCLUDE [environment-variables](environment-variables.md)]\n",
      "\n",
      "## Create an assistant\n",
      "\n",
      "In our code we are going to specify the following values:\n",
      "\n",
      "# Getting started with Azure OpenAI Assistants (Preview)\n",
      "\n",
      "Azure OpenAI Assistants (Preview) allows you to create AI assistants tailored to your needs through custom instructions and augmented by advanced tools like code interpreter, and custom functions. In this article we'll provide an in-depth walkthrough of getting started with the Assistants API.\n",
      "\n",
      "## Assistants support\n",
      "\n",
      "### Region and model support\n",
      "\n",
      "The [models page](../concepts/models.md#assistants-preview) contains the most up-to-date information on regions/models where Assistants are currently supported.\n",
      "\n",
      "### API Version\n",
      "\n",
      "- `2024-02-15-preview`\n",
      "\n",
      "### Supported file types\n",
      "\n",
      "|File format|MIME Type|Code Interpreter |\n",
      "|---|---|---|\n",
      "|.c| text/x-c |✅|\n",
      "|.cpp|text/x-c++ |✅|\n",
      "|.csv|application/csv|✅|\n",
      "|.docx|application/vnd.openxmlformats-officedocument.wordprocessingml.document|✅|\n",
      "|.html|text/html|✅|\n",
      "|.java|text/x-java|✅|\n",
      "|.json|application/json|✅|\n",
      "|.md|text/markdown| ✅ |\n",
      "|.pdf|application/pdf|✅|\n",
      "|.php|text/x-php|✅|\n",
      "|.pptx|application/vnd.openxmlformats-officedocument.presentationml.presentation|✅|\n",
      "|.py|text/x-python|✅|\n",
      "|.py|text/x-script.python|✅|\n",
      "|.rb|text/x-ruby|✅|\n",
      "|.tex|text/x-tex|✅|\n",
      "|.txt|text/plain|✅|\n",
      "|.css|text/css|✅|\n",
      "|.jpeg|image/jpeg|✅|\n",
      "|.jpg|image/jpeg|✅|\n",
      "|.js|text/javascript|✅|\n",
      "|.gif|image/gif|✅|\n",
      "|.png|image/png|✅|\n",
      "|.tar|application/x-tar|✅|\n",
      "|.ts|application/typescript|✅|\n",
      "|.xlsx|application/vnd.openxmlformats-officedocument.spreadsheetml.sheet|✅|\n",
      "|.xml|application/xml or \"text/xml\"|✅|\n",
      "|.zip|application/zip|✅|\n",
      "\n",
      "### Tools\n",
      "\n",
      "An individual assistant can access up to 128 tools including `code interpreter`, but you can also define your own custom tools via [functions](./assistant-functions.md).\n",
      "\n",
      "### Files\n",
      "\n",
      "Files can be uploaded via Studio, or programmatically. The `file_ids` parameter is required to give tools like `code_interpreter` access to files. When using the File upload endpoint, you must have the `purpose` set to assistants to be used with the Assistants API.\n",
      "\n",
      "## Assistants playground\n",
      "\n",
      "We provide a walkthrough of the Assistants playground in our [quickstart guide](../assistants-quickstart.md). This provides a no-code environment to test out the capabilities of assistants.\n",
      "\n",
      "## Assistants components\n",
      "\n",
      "| **Component** | **Description** |\n",
      "|---|---|\n",
      "| **Assistant** | Custom AI that uses Azure OpenAI models in conjunction with tools. |\n",
      "|**Thread** | A conversation session between an Assistant and a user. Threads store Messages and automatically handle truncation to fit content into a model’s context.|\n",
      "| **Message** | A message created by an Assistant or a user. Messages can include text, images, and other files. Messages are stored as a list on the Thread. |\n",
      "|**Run** | Activation of an Assistant to begin running based on the contents of the Thread. The Assistant uses its configuration and the Thread’s Messages to perform tasks by calling models and tools. As part of a Run, the Assistant appends Messages to the Thread.|\n",
      "|**Run Step** | A detailed list of steps the Assistant took as part of a Run. An Assistant can call tools or create Messages during it’s run. Examining Run Steps allows you to understand how the Assistant is getting to its final results. |\n",
      "\n",
      "## Setting up your first Assistant\n",
      "\n",
      "### Create an assistant\n",
      "\n",
      "For this example we'll create an assistant that writes code to generate visualizations using the capabilities of the `code_interpreter` tool. The examples below are intended to be run sequentially in an environment like [Jupyter Notebooks](https://jupyter.org/).\n",
      "\n",
      "```Python\n",
      "import os\n",
      "import json\n",
      "from openai import AzureOpenAI\n",
      "    \n",
      "client = AzureOpenAI(\n",
      "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
      "    api_version=\"2024-02-15-preview\",\n",
      "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
      "    )\n",
      "\n",
      "\n",
      "\n",
      "user:\n",
      "## User Question\n",
      "show OpenAI assistant api sample code in python\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = Template(simple_response_template, trim_blocks=True, keep_trailing_newline=True).render(\n",
    "    context=context,\n",
    "    chat_history=chat_history,\n",
    "    user_query=query\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6581b43a-aae5-43cf-a434-8486126f5f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(query, chat_history, template, model=MODEL):\n",
    "\n",
    "    context, metadata = get_context(query)\n",
    "    \n",
    "    prompt = Template(template, trim_blocks=True, keep_trailing_newline=True).render(\n",
    "        context=context,\n",
    "        chat_history=chat_history,\n",
    "        user_query=query\n",
    "    )\n",
    "    \n",
    "    messages = parse_chat(prompt)\n",
    "    \n",
    "    return _chat_gpt(messages, model), metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434319c-38ec-4a3c-a783-07347d7eed80",
   "metadata": {},
   "source": [
    "## Very Simple Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74ac00c9-4d1c-48ce-9057-3dbadda44248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is OpenAI assistant api? \n",
      ">  The OpenAI Assistants API is a feature of Azure OpenAI Service that allows developers to create applications with sophisticated copilot-like experiences. It enables developers to build custom AI assistants that can sift through data, suggest solutions, and automate tasks. The Assistants API provides a stateful evolution of the chat completion API, supporting persistent automatically managed threads and allowing developers to easily manage conversation state and chat threads. It also provides access to tools such as code interpreter and function calling. The Assistants API is built on the same capabilities as OpenAI's GPT product and can be used for various use cases such as AI-powered product recommenders, coding assistants, and chatbots.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"What is OpenAI assistant api?\"  \n",
    "response, metadata = get_response(query, chat_history, simple_response_template)\n",
    "chat_history.append([query, response])\n",
    "print(query, \"\\n> \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8a3e221-6acf-4333-be5f-cf4e80dd945c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.879656,\n",
       "  'chunk_id': '0',\n",
       "  'parent_id': 'assistants.md',\n",
       "  'title': 'Azure OpenAI Service Assistant API concepts'},\n",
       " {'score': 0.86666685,\n",
       "  'chunk_id': '0',\n",
       "  'parent_id': 'assistant.md',\n",
       "  'title': 'How to create Assistants with Azure OpenAI Service'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6967d62-2377-4442-9dcc-2ebfc4e4227b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is Google \n",
      ">  Google is a multinational technology company that specializes in Internet-related services and products. It was founded in 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University. Google is best known for its search engine, which is the most widely used search engine in the world. In addition to search, Google offers a wide range of products and services, including online advertising technologies, cloud computing, software, hardware, and more. Google's mission is to organize the world's information and make it universally accessible and useful.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Google\"\n",
    "response, metadata = get_response(query, chat_history, simple_response_template)\n",
    "chat_history.append([query, response])\n",
    "print(query, \"\\n> \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf8b0757-8622-4442-a081-992938c0cdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.7866772,\n",
       "  'chunk_id': '6',\n",
       "  'parent_id': 'prompt-chat-completion.md',\n",
       "  'title': 'How to work with prompt engineering and the Chat Completion API'},\n",
       " {'score': 0.7863357,\n",
       "  'chunk_id': '4',\n",
       "  'parent_id': 'prompt-engineering.md',\n",
       "  'title': 'Azure OpenAI Service | Introduction to Prompt engineering'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19eeae3-c7ad-4fc1-8c57-4eb786dcb680",
   "metadata": {},
   "source": [
    "## Grounded Prompt\n",
    "\n",
    "ground response using `ground_response_template`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "929761c5-ab7f-4bb2-a488-5fa5e96dc2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is OpenAI assistant api? \n",
      ">  The OpenAI Assistants API is a feature of Azure OpenAI Service that allows developers to create applications with sophisticated copilot-like experiences. It enables developers to build custom AI assistants that can sift through data, suggest solutions, and automate tasks. The Assistants API provides a stateful solution for managing conversation state, chat threads, tool integrations, retrieval documents, and code execution. It supports persistent automatically managed threads and allows developers to access multiple tools in parallel. The API is built on the capabilities of OpenAI's GPT product and can be used for various use cases such as AI-powered product recommenders, coding assistants, employee Q&A chatbots, and more.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"What is OpenAI assistant api?\"  \n",
    "response, metadata = get_response(query, chat_history, ground_response_template)\n",
    "chat_history.append([query, response])\n",
    "print(query, \"\\n> \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdf93208-6823-4425-95e3-41641f13017f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is Google \n",
      ">  Sorry, I don't know.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Google\"\n",
    "response, metadata = get_response(query, chat_history, ground_response_template)\n",
    "chat_history.append([query, response])\n",
    "print(query, \"\\n> \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c6ceac-31b8-4be4-aa5b-f5799e384586",
   "metadata": {},
   "source": [
    "## Condensed Question\n",
    "\n",
    "example of condense question:\n",
    "\n",
    "- first question \"what is assistant api?\"\n",
    "- second question \"show sample code in python\"\n",
    "\n",
    "intent of second question is \"show sample code for assistant api in python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7b46424-bdff-47fc-85a4-4562df5b3147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is OpenAI assistant api? \n",
      ">  The OpenAI Assistants API is a feature of Azure OpenAI Service that allows developers to create applications with sophisticated copilot-like experiences. It enables developers to build custom AI assistants that can sift through data, suggest solutions, and automate tasks. The Assistants API provides a stateful solution for managing conversation state, chat threads, tool integrations, retrieval documents, and code execution. It supports persistent automatically managed threads and allows developers to access multiple tools in parallel. The API is built on the capabilities of OpenAI's GPT product and can be used for various use cases such as AI-powered product recommenders, coding assistants, employee Q&A chatbots, and more.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"What is OpenAI assistant api?\"  \n",
    "response, metadata = get_response(query, chat_history, ground_response_template)\n",
    "chat_history.append([query, response])\n",
    "print(query, \"\\n> \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54028a9d-9a71-4dca-a597-abd07646f0fc",
   "metadata": {},
   "source": [
    "> unrelated response by retrieving wrong documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76763ff9-9c63-447d-acd9-f667f64459b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show sample code in python \n",
      ">  Sure! Here's an example of a Python code snippet:\n",
      "\n",
      "```python\n",
      "# This is a simple Python program\n",
      "# that prints \"Hello, World!\" to the console\n",
      "\n",
      "print(\"Hello, World!\")\n",
      "```\n",
      "\n",
      "This code will output the text \"Hello, World!\" when executed. Let me know if you need any further assistance!\n"
     ]
    }
   ],
   "source": [
    "query = \"show sample code in python\"\n",
    "response, metadata = get_response(query, chat_history, ground_response_template)\n",
    "chat_history.append([query, response])\n",
    "print(query, \"\\n> \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a343f37-fa0a-46e9-8591-8acf21af23ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show OpenAI assistant api sample code in python \n",
      ">  Sure! Here's an example of how you can use the OpenAI Assistant API in Python:\n",
      "\n",
      "```python\n",
      "import os\n",
      "from openai import AzureOpenAI\n",
      "\n",
      "# Create an instance of the AzureOpenAI class\n",
      "client = AzureOpenAI(\n",
      "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
      "    api_version=\"2024-02-15-preview\",\n",
      "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
      ")\n",
      "\n",
      "# Define your assistant parameters\n",
      "assistant_id = \"<your-assistant-id>\"\n",
      "message = {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"Hello, how can I assist you today?\"\n",
      "}\n",
      "\n",
      "# Call the assistant API\n",
      "response = client.assistants.create_message(assistant_id, message)\n",
      "\n",
      "# Print the assistant's response\n",
      "print(response[\"results\"][0][\"content\"])\n",
      "```\n",
      "\n",
      "Make sure to replace `<your-assistant-id>` with the ID of your assistant. You'll also need to set the `AZURE_OPENAI_KEY` and `AZURE_OPENAI_ENDPOINT` environment variables with your Azure OpenAI API key and endpoint respectively.\n",
      "\n",
      "Let me know if you have any other questions!\n"
     ]
    }
   ],
   "source": [
    "query = \"show OpenAI assistant api sample code in python\"\n",
    "response, metadata = get_response(query, chat_history, ground_response_template)\n",
    "chat_history.append([query, response])\n",
    "print(query, \"\\n> \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b542bf-05e7-4869-a150-5430c81b0be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
