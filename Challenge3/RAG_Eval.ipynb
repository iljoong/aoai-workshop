{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3ce09c-2b1f-4912-af44-33b4592e67a2",
   "metadata": {},
   "source": [
    "# RAG Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885ee653-e41c-4a48-85c2-9edb52161179",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f420f0-4270-4a1d-933b-6aa974e4482b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39fc3e81-86dc-4d1a-b9a7-f2691d706fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "MODEL = \"gpt-4o\"\n",
    "MODEL_GPT35 = \"gpt-35-turbo\"\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.environ['AZURE_OPENAI_KEY'],\n",
    "    #api_version=\"2024-10-01-preview\",\n",
    "    api_version=\"2024-08-01-preview\",\n",
    "    azure_endpoint = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abbe964c-729d-4dd4-b3b3-de2fcc312e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _chat_gpt(messages, model=MODEL, temp=0, topp=0.1):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temp,\n",
    "        max_tokens=2000,\n",
    "        top_p=topp\n",
    "    )   \n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6a4f87-683b-4dcb-88da-622599dd6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "# Variables not used here do not need to be updated in your .env file\n",
    "endpoint = os.environ[\"AZSCH_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.environ[\"AZSCH_KEY\"])\n",
    "\n",
    "index_name = os.environ[\"AZSCH_INDEX_NAME\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093138f8-4a3e-47e3-b3e8-a550b94feade",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3151cca2-1e1a-4e84-a6cc-8ce7b3ef26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "\n",
    "topK = 2\n",
    "# Pure Vector Search\n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "\n",
    "def get_context(text):\n",
    "    vector_query = VectorizableTextQuery(text=text, k_nearest_neighbors=topK, fields=\"vector\", exhaustive=True)\n",
    "    results = search_client.search(  \n",
    "        search_text=None,  \n",
    "        vector_queries= [vector_query],\n",
    "        select=[\"parent_id\", \"chunk_id\", \"chunk\", \"title\"],\n",
    "        top=topK\n",
    "    )  \n",
    "\n",
    "    context = \"\"\n",
    "    metadata = []\n",
    "    for result in results:  \n",
    "        context = context + result['chunk'] + \"\\n\\n\"\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a65f8f-c28e-4af3-8940-08f7d34c6343",
   "metadata": {},
   "source": [
    "## Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dc02f5b-a1da-44c8-b445-9937ff6daff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt templates\n",
    "from jinja2 import Template\n",
    "from common import parse_chat\n",
    "\n",
    "with open('./reply_simple.jinja2') as file:\n",
    "    simple_response_template = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6581b43a-aae5-43cf-a434-8486126f5f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(query, chat_history, template, model=MODEL):\n",
    "\n",
    "    context = get_context(query)\n",
    "    \n",
    "    prompt = Template(template, trim_blocks=True, keep_trailing_newline=True).render(\n",
    "        context=context,\n",
    "        chat_history=chat_history,\n",
    "        user_query=query\n",
    "    )\n",
    "    \n",
    "    messages = parse_chat(prompt)\n",
    "    \n",
    "    return _chat_gpt(messages, model), context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434319c-38ec-4a3c-a783-07347d7eed80",
   "metadata": {},
   "source": [
    "## Groundness - GPT-3.5-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcce47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import measure_groundness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74ac00c9-4d1c-48ce-9057-3dbadda44248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q> What is OpenAI assistant api? \n",
      "A>  The OpenAI Assistants API is a powerful tool that allows developers to create custom AI assistants. These assistants can understand and respond to user queries, provide recommendations, automate tasks, and more. The API is built on OpenAI's GPT (Generative Pre-trained Transformer) models, which are trained on a wide range of data to generate human-like responses. With the Assistants API, developers can easily build conversational AI applications without having to manage conversation state or handle complex integrations. The API supports features like persistent threads, code interpretation, and function calling, making it easier to create sophisticated AI assistants.\n",
      "groundness: <Score: 4>\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "question = \"What is OpenAI assistant api?\"  \n",
    "answer, context = get_response(question, chat_history, simple_response_template, model=MODEL_GPT35)\n",
    "chat_history.append([question, answer])\n",
    "print(\"Q>\", question, \"\\nA> \", answer)\n",
    "\n",
    "score = measure_groundness(question, answer, context)\n",
    "print(\"groundness:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6967d62-2377-4442-9dcc-2ebfc4e4227b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q> What is Google \n",
      "A>  Google is a multinational technology company that specializes in Internet-related services and products. It was founded in 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University. Google's mission is to organize the world's information and make it universally accessible and useful. The company is best known for its search engine, which is the most widely used search engine in the world. Google also offers a wide range of other products and services, including online advertising technologies, cloud computing, software, hardware, and more.\n",
      "groundness: <Score: 1>\n"
     ]
    }
   ],
   "source": [
    "question = \"What is Google\" \n",
    "answer, context = get_response(question, chat_history, simple_response_template, model=MODEL_GPT35)\n",
    "chat_history.append([question, answer])\n",
    "print(\"Q>\", question, \"\\nA> \", answer)\n",
    "\n",
    "score = measure_groundness(question, answer, context)\n",
    "print(\"groundness:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b89d53c",
   "metadata": {},
   "source": [
    "## Groundness - GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08678a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q> What is OpenAI assistant api? \n",
      "A>  The OpenAI Assistants API is a feature of the Azure OpenAI Service that allows developers to create sophisticated AI assistants with capabilities similar to copilot experiences. This API simplifies the process of building custom AI assistants by managing conversation states, integrating tools, retrieving documents, and executing code. It supports persistent, automatically managed conversation threads, allowing developers to append new messages without worrying about context window constraints. The Assistants API can access multiple tools in parallel, such as code interpreters and custom functions, to perform various tasks. This makes it easier to develop applications like product recommenders, sales analysts, coding assistants, and more.\n",
      "groundness: <Score: 5>\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "question = \"What is OpenAI assistant api?\"  \n",
    "answer, context = get_response(question, chat_history, simple_response_template)\n",
    "chat_history.append([question, answer])\n",
    "print(\"Q>\", question, \"\\nA> \", answer)\n",
    "\n",
    "score = measure_groundness(question, answer, context)\n",
    "print(\"groundness:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52f8ea9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q> What is Google \n",
      "A>  The provided text does not contain information about Google. Please refer to other sources for information on Google.\n",
      "groundness: <Score: 5>\n"
     ]
    }
   ],
   "source": [
    "question = \"What is Google\" \n",
    "answer, context = get_response(question, chat_history, simple_response_template)\n",
    "chat_history.append([question, answer])\n",
    "print(\"Q>\", question, \"\\nA> \", answer)\n",
    "\n",
    "score = measure_groundness(question, answer, context)\n",
    "print(\"groundness:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6502c7b",
   "metadata": {},
   "source": [
    "## Groundness - Condensed Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36b542bf-05e7-4869-a150-5430c81b0be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q> show sample code in python \n",
      "A>  Sure! Could you please specify what kind of sample code you are looking for in Python? For example, are you interested in data analysis, web development, machine learning, or something else? Let me know so I can provide a relevant example.\n",
      "\n",
      "groundness: <Score: 1>\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "question = \"What is OpenAI assistant api?\"  \n",
    "answer, context = get_response(question, chat_history, simple_response_template)\n",
    "chat_history.append([question, answer])\n",
    "\n",
    "question = \"show sample code in python\"  \n",
    "answer, context = get_response(question, chat_history, simple_response_template)\n",
    "chat_history.append([question, answer])\n",
    "print(\"Q>\", question, \"\\nA> \", answer)\n",
    "\n",
    "score = measure_groundness(question, answer, context)\n",
    "print(\"\\ngroundness:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99646431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
