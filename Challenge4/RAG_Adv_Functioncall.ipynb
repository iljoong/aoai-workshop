{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RAG with function calling\n",
    "\n",
    "Advanced reasoning with function calling:\n",
    "- Rewriting user's question to get a better search result.\n",
    "- Multi-step function calling plan to get complex user's question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "MODEL = \"gpt-4o\"\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.environ['AZURE_OPENAI_KEY'],\n",
    "    api_version='2024-11-01-preview',\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function call\n",
    "retrieve_function = {\n",
    "    \"name\": \"search_document\",\n",
    "    \"description\": \"search and get Azure OpenAI and Generative AI related information.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Re-written and detailed question to find the right information. e.g., API, technology, and etc.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"question\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.user_function import search_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tool(tool_call):\n",
    "    available_functions = {\n",
    "        \"search_document\": search_document,\n",
    "    }  # only one function in this example, but you can have multiple\n",
    "\n",
    "    function_name = tool_call.function.name\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    return {\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"role\": \"tool\",\n",
    "        \"name\": function_name,\n",
    "        \"content\": f\"{function_response}\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(message_history):\n",
    "\n",
    "    settings = {\n",
    "        \"model\": MODEL,\n",
    "        \"tool_choice\": \"auto\",\n",
    "        \"tools\": [\n",
    "            {\"type\": \"function\", \"function\": retrieve_function},\n",
    "        ],\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        messages=message_history, \n",
    "        **settings\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message\n",
    "    message_history.append(message.to_dict())\n",
    "\n",
    "    for tool_call in message.tool_calls or []:\n",
    "        if tool_call.type == \"function\":\n",
    "            tool_message = call_tool(tool_call)\n",
    "            message_history.append(tool_message)\n",
    "\n",
    "    return message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITER = 5\n",
    "\n",
    "def run_conversation(message_history, question):\n",
    "\n",
    "    message_history.append({\"role\": \"user\", \"content\": question})\n",
    "    \n",
    "    length_of_chat = len(message_history)\n",
    "    cur_iter = 0\n",
    "\n",
    "    while cur_iter < MAX_ITER:\n",
    "        message_history = call_llm(message_history)\n",
    "        message = message_history[-1]\n",
    "        \n",
    "        cur_iter += 1\n",
    "        if message['role'] == \"tool\":\n",
    "            # run call_llm again to get the response\n",
    "            continue\n",
    "        else:\n",
    "            answer = \"\"\n",
    "            for past_message in message_history[length_of_chat:]:\n",
    "                if past_message[\"role\"] == \"assistant\" and past_message[\"content\"] is not None:\n",
    "                    answer += past_message['content'] + \"\\n\"\n",
    "\n",
    "            return answer, message_history\n",
    "\n",
    "    return \"exceeded max iterations\", message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m tool: search the document of \"What is Assistant API?\" \u001b[0m\n",
      "The Assistant API is a feature of the Azure OpenAI Service, currently in public preview, designed to simplify the creation of applications with advanced copilot-like experiences. It allows developers to build AI assistants that can sift through data, suggest solutions, and automate tasks. Unlike the stateless chat completions API, the Assistants API is stateful, meaning it automatically manages conversation threads and state, making it easier for developers to handle conversation context and integrate tools.\n",
      "\n",
      "Key features of the Assistants API include:\n",
      "\n",
      "- **Persistent Threads**: Automatically managed conversation threads that handle context window constraints.\n",
      "- **Tool Integration**: Ability to access multiple tools in parallel, such as Code Interpreter and function calling.\n",
      "- **Run and Run Steps**: Mechanisms to activate and track the steps an Assistant takes during a task.\n",
      "\n",
      "The Assistants API is built on the same capabilities that power OpenAIâ€™s GPT product and can be used for various applications like product recommendation, sales analysis, coding assistance, and more. Developers can start building with the API or use the no-code Assistants playground in the Azure OpenAI Studio.\n",
      "\n",
      "-------------------\n",
      "\u001b[34m tool: search the document of \"sample code for Assistant API in Python\" \u001b[0m\n",
      "Here's a sample Python code to create an assistant file using the Azure OpenAI Assistants API:\n",
      "\n",
      "```python\n",
      "from openai import AzureOpenAI\n",
      "import os\n",
      "\n",
      "# Initialize the AzureOpenAI client\n",
      "client = AzureOpenAI(\n",
      "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
      "    api_version=\"2024-02-15-preview\",\n",
      "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
      ")\n",
      "\n",
      "# Create an assistant file\n",
      "assistant_file = client.beta.assistants.files.create(\n",
      "  assistant_id=\"asst_abc123\",\n",
      "  file_id=\"assistant-abc123\"\n",
      ")\n",
      "\n",
      "# Print the created assistant file details\n",
      "print(assistant_file)\n",
      "```\n",
      "\n",
      "This code snippet demonstrates how to create an assistant file using the Azure OpenAI Python SDK. Make sure to replace `\"asst_abc123\"` and `\"assistant-abc123\"` with your actual assistant ID and file ID. Also, ensure that your environment variables `AZURE_OPENAI_KEY` and `AZURE_OPENAI_ENDPOINT` are set with your Azure OpenAI API key and endpoint, respectively.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message_history = []\n",
    "\n",
    "question = \"What is Assistant API?\"\n",
    "\n",
    "response, message_history = run_conversation(message_history, question)\n",
    "print(response)\n",
    "print(\"-------------------\")\n",
    "question = \"show sample code in python\"\n",
    "response, message_history = run_conversation(message_history, question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'What is Assistant API?'},\n",
       " {'content': None,\n",
       "  'role': 'assistant',\n",
       "  'tool_calls': [{'id': 'call_eKXKhGFqxGkTEBduZMqyZ3hN',\n",
       "    'function': {'arguments': '{\"question\":\"What is Assistant API?\"}',\n",
       "     'name': 'search_document'},\n",
       "    'type': 'function'}]},\n",
       " {'tool_call_id': 'call_eKXKhGFqxGkTEBduZMqyZ3hN',\n",
       "  'role': 'tool',\n",
       "  'name': 'search_document',\n",
       "  'content': '# Azure OpenAI Assistants API (Preview)\\n\\nAssistants, a new feature of Azure OpenAI Service, is now available in public preview. Assistants API makes it easier for developers to create applications with sophisticated copilot-like experiences that can sift through data, suggest solutions, and automate tasks.\\n\\n## Overview\\n\\nPreviously, building custom AI assistants needed heavy lifting even for experienced developers. While the chat completions API is lightweight and powerful, it\\'s inherently stateless, which means that developers had to manage conversation state and chat threads, tool integrations, retrieval documents and indexes, and execute code manually.\\n\\nThe Assistants API, as the stateful evolution of the chat completion API, provides a solution for these challenges.\\nAssistants API supports persistent automatically managed threads. This means that as a developer you no longer need to develop conversation state management systems and work around a modelâ€™s context window constraints. The Assistants API will automatically handle the optimizations to keep the thread below the max context window of your chosen model. Once you create a Thread, you can simply append new messages to it as users respond. Assistants can also access multiple tools in parallel, if needed. These tools include:\\n\\n- [Code Interpreter](../how-to/code-interpreter.md)\\n- [Function calling](../how-to/assistant-functions.md)\\n\\nAssistant API is built on the same capabilities that power OpenAIâ€™s GPT product. Some possible use cases range from AI-powered product recommender, sales analyst app, coding assistant, employee Q&A chatbot, and more. Start building on the no-code Assistants playground on the Azure OpenAI Studio or start building with the API.\\n\\n> [!IMPORTANT]\\n> Retrieving untrusted data using Function calling, Code Interpreter with file input, and Assistant Threads functionalities could compromise the security of your Assistant, or the application that uses the Assistant. Learn about mitigation approaches [here](https://aka.ms/oai/assistant-rai).\\n\\n## Assistants playground\\n\\nWe provide a walkthrough of the Assistants playground in our [quickstart guide](../assistants-quickstart.md). This provides a no-code environment to test out the capabilities of assistants.\\n\\n## Assistants components\\n\\n| **Component** | **Description** |\\n|---|---|\\n| **Assistant** | Custom AI that uses Azure OpenAI models in conjunction with tools. |\\n|**Thread** | A conversation session between an Assistant and a user. Threads store Messages and automatically handle truncation to fit content into a modelâ€™s context.|\\n| **Message** | A message created by an Assistant or a user. Messages can include text, images, and other files. Messages are stored as a list on the Thread. |\\n|**Run** | Activation of an Assistant to begin running based on the contents of the Thread. The Assistant uses its configuration and the Threadâ€™s Messages to perform tasks by calling models and tools. As part of a Run, the Assistant appends Messages to the Thread.|\\n|**Run Step** | A detailed list of steps the Assistant took as part of a Run. An Assistant can call tools or create Messages during itâ€™s run. Examining Run Steps allows you to understand how the Assistant is getting to its final results. |\\n\\n## See also\\n\\n* Learn more about Assistants and [Code Interpreter](../how-to/code-interpreter.md)\\n* Learn more about Assistants and [function calling](../how-to/assistant-functions.md)\\n* [Azure OpenAI Assistants API samples](https://github.com/Azure-Samples/azureai-samples/tree/main/scenarios/Assistants)\\n[Reference 0](assistants.md)\\n\\n```\\n{\"role\": \"system\", \"content\": \"Assistant is an intelligent chatbot designed to help users answer technical questions about Azure OpenAI Serivce. Only answer questions using the context below and if you\\'re not sure of an answer, you can say \\'I don\\'t know\\'.\\n\\nContext:\\n- Azure OpenAI Service provides REST API access to OpenAI\\'s powerful language models including the GPT-3, Codex and Embeddings model series.\\n- Azure OpenAI Service gives customers advanced language AI with OpenAI GPT-3, Codex, and DALL-E models with the security and enterprise promise of Azure. Azure OpenAI co-develops the APIs with OpenAI, ensuring compatibility and a smooth transition from one to the other.\\n- At Microsoft, we\\'re committed to the advancement of AI driven by principles that put people first. Microsoft has made significant investments to help guard against abuse and unintended harm, which includes requiring applicants to show well-defined use cases, incorporating Microsoftâ€™s principles for responsible AI use.\"\\n},\\n{\"role\": \"user\", \"content\": \"What is Azure OpenAI Service?\"}\\n```\\n\\n#### Few shot learning with Chat Completion\\n\\nYou can also give few shot examples to the model. The approach for few shot learning has changed slightly because of the new prompt format. You can now include a series of messages between the user and the assistant in the prompt as few shot examples. These examples can be used to seed answers to common questions to prime the model or teach particular behaviors to the model.\\n\\nThis is only one example of how you can use few shot learning with GPT-35-Turbo and GPT-4. You can experiment with different approaches to see what works best for your use case.\\n\\n```\\n{\"role\": \"system\", \"content\": \"Assistant is an intelligent chatbot designed to help users answer their tax related questions. \"},\\n{\"role\": \"user\", \"content\": \"When do I need to file my taxes by?\"},\\n{\"role\": \"assistant\", \"content\": \"In 2023, you will need to file your taxes by April 18th. The date falls after the usual April 15th deadline because April 15th falls on a Saturday in 2023. For more details, see https://www.irs.gov/filing/individuals/when-to-file.\"},\\n{\"role\": \"user\", \"content\": \"How can I check the status of my tax refund?\"},\\n{\"role\": \"assistant\", \"content\": \"You can check the status of your tax refund by visiting https://www.irs.gov/refunds\"}\\n```\\n\\n#### Using Chat Completion for non-chat scenarios\\n\\nThe Chat Completion API is designed to work with multi-turn conversations, but it also works well for non-chat scenarios.\\n\\nFor example, for an entity extraction scenario, you might use the following prompt:\\n\\n```\\n{\"role\": \"system\", \"content\": \"You are an assistant designed to extract entities from text. Users will paste in a string of text and you will respond with entities you\\'ve extracted from the text as a JSON object. Here\\'s an example of your output format:\\n{\\n   \"name\": \"\",\\n   \"company\": \"\",\\n   \"phone_number\": \"\"\\n}\"},\\n{\"role\": \"user\", \"content\": \"Hello. My name is Robert Smith. I\\'m calling from Contoso Insurance, Delaware. My colleague mentioned that you are interested in learning about our comprehensive benefits policy. Could you give me a call back at (555) 346-9322 when you get a chance so we can go over the benefits?\"}\\n```\\n\\n## Creating a basic conversation loop\\n\\nThe examples so far have shown you the basic mechanics of interacting with the Chat Completion API. This example shows you how to create a conversation loop that performs the following actions:\\n\\n- Continuously takes console input, and properly formats it as part of the messages list as user role content.\\n- Outputs responses that are printed to the console and formatted and added to the messages list as assistant role content.\\n\\nThis means that every time a new question is asked, a running transcript of the conversation so far is sent along with the latest question. Since the model has no memory, you need to send an updated transcript with each new question or the model will lose context of the previous questions and answers.\\n\\n\\n# [OpenAI Python 0.28.1](#tab/python)\\n\\n```python\\nimport os\\nimport openai\\nopenai.api_type = \"azure\"\\nopenai.api_version = \"2023-05-15\" \\nopenai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  # Your Azure OpenAI resource\\'s endpoint value.\\nopenai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\\n\\nconversation=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\\n[Reference 1](chat-completion.md)'},\n",
       " {'content': 'The Assistant API is a feature of the Azure OpenAI Service, currently in public preview, designed to simplify the creation of applications with advanced copilot-like experiences. It allows developers to build AI assistants that can sift through data, suggest solutions, and automate tasks. Unlike the stateless chat completions API, the Assistants API is stateful, meaning it automatically manages conversation threads and state, making it easier for developers to handle conversation context and integrate tools.\\n\\nKey features of the Assistants API include:\\n\\n- **Persistent Threads**: Automatically managed conversation threads that handle context window constraints.\\n- **Tool Integration**: Ability to access multiple tools in parallel, such as Code Interpreter and function calling.\\n- **Run and Run Steps**: Mechanisms to activate and track the steps an Assistant takes during a task.\\n\\nThe Assistants API is built on the same capabilities that power OpenAIâ€™s GPT product and can be used for various applications like product recommendation, sales analysis, coding assistance, and more. Developers can start building with the API or use the no-code Assistants playground in the Azure OpenAI Studio.',\n",
       "  'role': 'assistant'},\n",
       " {'role': 'user', 'content': 'show sample code in python'},\n",
       " {'content': None,\n",
       "  'role': 'assistant',\n",
       "  'tool_calls': [{'id': 'call_xuANDW8VA3v5VhLR2okzWRKj',\n",
       "    'function': {'arguments': '{\"question\":\"sample code for Assistant API in Python\"}',\n",
       "     'name': 'search_document'},\n",
       "    'type': 'function'}]},\n",
       " {'tool_call_id': 'call_xuANDW8VA3v5VhLR2okzWRKj',\n",
       "  'role': 'tool',\n",
       "  'name': 'search_document',\n",
       "  'content': '### Example create assistant file request\\n\\n# [Python 1.x](#tab/python)\\n\\n```python\\nfrom openai import AzureOpenAI\\n    \\nclient = AzureOpenAI(\\n    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \\n    api_version=\"2024-02-15-preview\",\\n    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\\n    )\\n\\nassistant_file = client.beta.assistants.files.create(\\n  assistant_id=\"asst_abc123\",\\n  file_id=\"assistant-abc123\"\\n)\\nprint(assistant_file)\\n```\\n\\n# [REST](#tab/rest)\\n\\n```console\\ncurl https://YOUR_RESOURCE_NAME.openai.azure.com/openai/assistants/{assistant_id}/files?api-version=2024-02-15-preview \\\\\\n  -H \"api-key: $AZURE_OPENAI_KEY\" \\\\\\n  -H \\'Content-Type: application/json\\' \\\\\\n  -d \\'{\\n       \"file_id\": \"assistant-abc123\"\\n     }\\'\\n```\\n\\n---\\n\\n## List assistants\\n\\n```http\\nGET https://YOUR_RESOURCE_NAME.openai.azure.com/openai/assistants?api-version=2024-02-15-preview\\n```\\n\\nReturns a list of all assistants.\\n\\n**Query parameters**\\n\\n|Parameter| Type | Required | Description |\\n|---|---|---|---|\\n| `limit` | integer | Optional | A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.|\\n| `order` | string | Optional - Defaults to desc | Sort order by the created_at timestamp of the objects. asc for ascending order and desc for descending order.|\\n| `after` | string | Optional | A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list. |\\n|`before`| string | Optional | A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list. |\\n\\n### Returns\\n\\nA list of [assistant](#assistant-object) objects\\n\\n### Example list assistants\\n\\n# [Python 1.x](#tab/python)\\n\\n```python\\nfrom openai import AzureOpenAI\\n    \\nclient = AzureOpenAI(\\n    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \\n    api_version=\"2024-02-15-preview\",\\n    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\\n    )\\n\\nmy_assistants = client.beta.assistants.list(\\n    order=\"desc\",\\n    limit=\"20\",\\n)\\nprint(my_assistants.data)\\n\\n```\\n\\n# [REST](#tab/rest)\\n\\n```console\\ncurl https://YOUR_RESOURCE_NAME.openai.azure.com/openai/assistants?api-version=2024-02-15-preview  \\\\\\n  -H \"api-key: $AZURE_OPENAI_KEY\" \\\\\\n  -H \\'Content-Type: application/json\\' \\n```\\n\\n---\\n\\n## List assistant files\\n\\n```http\\nGET https://YOUR_RESOURCE_NAME.openai.azure.com/openai/assistants/{assistant_id}/files?api-version=2024-02-15-preview\\n```\\n\\nReturns a list of assistant files.\\n\\n**Path parameters**\\n\\n|Parameter| Type | Required | Description |\\n|---|---|---|---|\\n| assistant_id | string | Required | The ID of the assistant the file belongs to. |\\n\\n**Query parameters**\\n[Reference 0](assistants-reference.md)\\n\\n# Assistants API (Preview) runs reference\\n\\nThis article provides reference documentation for Python and REST for the new Assistants API (Preview). More in-depth step-by-step guidance is provided in the [getting started guide](./how-to/assistant.md).\\n\\n## Create run\\n\\n```http\\nPOST https://YOUR_RESOURCE_NAME.openai.azure.com/openai/threads/{thread_id}/runs?api-version=2024-02-15-preview\\n```\\n\\nCreate a run.\\n\\n**Path parameter**\\n\\n|Parameter| Type | Required | Description |\\n|---|---|---|---|\\n|`thread_id` | string | Required | The ID of the thread to create a message for. |\\n\\n**Request body**\\n\\n|Name | Type | Required | Description |\\n|---  |---   |---       |--- |\\n| `assistant_id` | string | Required | The ID of the assistant to use to execute this run. |\\n| `model` | string or null | Optional | The model deployment name to be used to execute this run. If a value is provided here, it will override the model deployment name associated with the assistant. If not, the model deployment name associated with the assistant will be used. |\\n| `instructions` | string or null | Optional | Overrides the instructions of the assistant. This is useful for modifying the behavior on a per-run basis. |\\n| `additional_instructions` | string or null | Optional | Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions. |\\n| `tools` | array or null | Optional | Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis. |\\n| `metadata` | map | Optional | Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long. |\\n\\n### Returns\\n\\nA run object.\\n\\n### Example create run request\\n\\n# [Python 1.x](#tab/python)\\n\\n```python\\nfrom openai import AzureOpenAI\\n    \\nclient = AzureOpenAI(\\n    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \\n    api_version=\"2024-02-15-preview\",\\n    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\\n    )\\n\\nrun = client.beta.threads.runs.create(\\n  thread_id=\"thread_abc123\",\\n  assistant_id=\"asst_abc123\"\\n)\\nprint(run)\\n```\\n\\n# [REST](#tab/rest)\\n\\n```console\\ncurl https://YOUR_RESOURCE_NAME.openai.azure.com/openai/threads/{thread_id}/runs?api-version=2024-02-15-preview \\\\\\n  -H \"api-key: $AZURE_OPENAI_KEY\" \\\\\\n  -H \\'Content-Type: application/json\\' \\\\\\n  -d \\'{\\n    \"assistant_id\": \"asst_abc123\"\\n  }\\'\\n```\\n\\n---\\n\\n## Create thread and run\\n\\n```http\\nPOST https://YOUR_RESOURCE_NAME.openai.azure.com/openai/threads/runs?api-version=2024-02-15-preview\\n```\\n\\nCreate a thread and run it in a single request.\\n\\n**Request Body**\\n\\n|Name | Type | Required | Description |\\n|---  |---   |---       |--- |\\n| `assistant_id` | string  | Required | The ID of the assistant to use to execute this run.|\\n| `thread` | object  | Optional | |\\n| `model` | string or null  | Optional | The ID of the Model deployment name to be used to execute this run. If a value is provided here, it will override the model deployment name associated with the assistant. If not, the model deployment name associated with the assistant will be used.|\\n| `instructions` | string or null  | Optional | Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.|\\n| `tools` | array or null  | Optional | Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.|\\n| `metadata` | map  | Optional | Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maximum of 512 characters long.|\\n\\n### Returns\\n\\nA run object.\\n\\n### Example create thread and run request\\n\\n# [Python 1.x](#tab/python)\\n[Reference 1](assistants-reference-runs.md)'},\n",
       " {'content': 'Here\\'s a sample Python code to create an assistant file using the Azure OpenAI Assistants API:\\n\\n```python\\nfrom openai import AzureOpenAI\\nimport os\\n\\n# Initialize the AzureOpenAI client\\nclient = AzureOpenAI(\\n    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \\n    api_version=\"2024-02-15-preview\",\\n    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\\n)\\n\\n# Create an assistant file\\nassistant_file = client.beta.assistants.files.create(\\n  assistant_id=\"asst_abc123\",\\n  file_id=\"assistant-abc123\"\\n)\\n\\n# Print the created assistant file details\\nprint(assistant_file)\\n```\\n\\nThis code snippet demonstrates how to create an assistant file using the Azure OpenAI Python SDK. Make sure to replace `\"asst_abc123\"` and `\"assistant-abc123\"` with your actual assistant ID and file ID. Also, ensure that your environment variables `AZURE_OPENAI_KEY` and `AZURE_OPENAI_ENDPOINT` are set with your Azure OpenAI API key and endpoint, respectively.',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
