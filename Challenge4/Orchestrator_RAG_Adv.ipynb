{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b87ca4a0-bcb9-427e-824a-373e3f4aac0f",
   "metadata": {},
   "source": [
    "# AI Orchestrator - RAG Advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c49d0c83-7c09-4578-a2cc-d3299524dd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f843749-02b3-4f89-b256-bac64968daba",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c1b2c57-897b-4cf7-8e6e-3d74c4adbe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "MODEL_GPT4 = \"gpt-4-turbo\"\n",
    "MODEL_GPT35 = \"gpt-35-turbo-1106\"\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.environ['SC_AOAI_KEY'],\n",
    "    api_version=\"2023-12-01-preview\",\n",
    "    azure_endpoint = os.environ['SC_AOAI_ENDPOINT']\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7742140-e892-42ad-86f5-32029c218255",
   "metadata": {},
   "source": [
    "# Entra ID authentication with Managed ID\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "MODEL_GPT4 = \"gpt-4-turbo\"\n",
    "MODEL_GPT35 = \"gpt-35-turbo-1106\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.environ['SC_AOAI_ENDPOINT'],\n",
    "    azure_ad_token_provider=get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"),\n",
    "    api_version=\"2023-12-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447d4d4c-0cd8-48ee-9618-0aaad4f67d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _chat_gpt(messages, model=MODEL_GPT35, temp=0.0, topp=0.1):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temp,\n",
    "        max_tokens=4000,\n",
    "        top_p=topp\n",
    "    )   \n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17cc2b52-a833-405b-80f2-8d85f2f99b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "endpoint = os.environ[\"AZSCH_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.environ[\"AZSCH_KEY\"])\n",
    "# managed id authentication\n",
    "#credential = DefaultAzureCredential()\n",
    "\n",
    "index_name = 'aoai-docs-idx'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9788cd97-b593-4ef2-af61-19d391d7ab4e",
   "metadata": {},
   "source": [
    "# Entra ID authentication with Managed ID\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "endpoint = os.environ[\"AZSCH_ENDPOINT\"]\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "index_name = 'aoai-docs-idx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80d1374-1903-4cf5-ba04-c5e35ac9f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt templates\n",
    "from jinja2 import Template\n",
    "from common import parse_chat\n",
    "\n",
    "with open('./determine_reply.jinja2') as file:\n",
    "    reply_template = file.read()\n",
    "\n",
    "with open('./determine_intent.jinja2') as file:\n",
    "    intent_template = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcb089d-c485-484b-999a-28eae0fd8489",
   "metadata": {},
   "source": [
    "## Intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "016a0fd3-64b2-4984-9671-6f51438e90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_intent(query, intent_history):\n",
    "    prompt = Template(intent_template, trim_blocks=True, keep_trailing_newline=True).render(\n",
    "        intent_history=intent_history,\n",
    "        query=query\n",
    "    )\n",
    "\n",
    "    messages = parse_chat(prompt)\n",
    "    \n",
    "    return _chat_gpt(messages)\n",
    "\n",
    "def extract_intent(input: str, query: str) -> str:\n",
    "  entries = None\n",
    "  if 'Single Intents:' in input:\n",
    "    entries = input.split('Single Intents:', 2)\n",
    "  elif 'Single Intent:' in input:\n",
    "    entries = input.split('Single Intent:', 2)\n",
    "  \n",
    "  if entries and len(entries) == 2:\n",
    "    return {\n",
    "      \"current_message_intent\": entries[0].strip(),\n",
    "      \"search_intents\": entries[1].strip()\n",
    "    }\n",
    "  return {\n",
    "      \"current_message_intent\": query,\n",
    "      \"search_intents\": query\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47a715cb-8ac9-4261-8629-563cfb54f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_search_intent(query, intent_history):\n",
    "    raw_intent = determine_intent(query, intent_history)\n",
    "    intent = extract_intent(raw_intent, query)\n",
    "    js = json.loads(intent['search_intents'])\n",
    "    \n",
    "    return js[0] if len(js) != 0 else \"\", raw_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f61067ad-5f2b-4f86-85ac-9463b43784b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is Assistant API?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_history = []\n",
    "query = \"What is Assistant API\"\n",
    "intent, raw_intent = get_search_intent(query, intent_history)\n",
    "intent_history.append(intent)\n",
    "intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "330fd785-c1c0-4cc4-9766-d0e910aa5fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show sample code for Assistant API in python \n",
      " Show some sample code in python for Assistant API\n",
      "Single Intents: [\"show sample code for Assistant API in python\"]\n"
     ]
    }
   ],
   "source": [
    "query = \"Show some sample code in python\"\n",
    "intent, raw_intent = get_search_intent(query, intent_history)\n",
    "intent_history.append(intent)\n",
    "print(intent, \"\\n\", raw_intent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e1dfd-2a85-4522-a9c3-e39658e22769",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0ba6780-ad97-4780-b1e9-7ae9399cb62b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from aisearch import AISearch\n",
    "from common import format_retrieved_documents\n",
    "\n",
    "def get_contenxt(intent):\n",
    "    search = AISearch(endpoint, index_name, credential)\n",
    "    docs = search.get_results(intent)\n",
    "    documentation, metadata = format_retrieved_documents(docs, 4000)\n",
    "\n",
    "    return documentation, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae414778-13d0-488b-8a2a-ac81bae4b5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'retrieved_documents\\': [{\\'[doc0]\\': {\\'title\\': \\'assistant.md\\', \\'content\\': \\'code.\"\\\\n    f\"When you are asked to create a visualization you should follow these steps:\"\\\\n    f\"1. Write the code.\"\\\\n    f\"2. Anytime you write new code display a preview of the code to show your work.\"\\\\n    f\"3. Run the code to confirm that it runs.\"\\\\n    f\"4. If the code is successful display the visualization.\"\\\\n    f\"5. If the code is unsuccessful display the error message and try to revise the code and rerun going through the steps from above again.\",\\\\n    tools=[{\"type\": \"code_interpreter\"}],\\\\n    model=\"gpt-4-1106-preview\" #You must replace this value with the deployment name for your model.\\\\n)\\\\n\\\\n```\\\\n\\\\nThere are a few details you should note from the configuration above:\\\\n\\\\n- We enable this assistant to access code interpreter with the line ` tools=[{\"type\": \"code_interpreter\"}],`. This gives the model access to a sand-boxed python environment to run and execute code to help formulating responses to a user\\\\\\'s question.\\\\n- In the instructions we remind the model that it can execute code. Sometimes the model needs help guiding it towards the right tool to solve a given query. If you know, you want to use a particular library to generate a certain response that you know is part of code interpreter it can help to provide guidance by saying something like \"Use Matplotlib to do x.\"\\\\n- Since this is Azure OpenAI the value you enter for `model=` **must match the deployment name**. By convention our docs will often use a deployment name that happens to match the model name to indicate which model was used when testing a given example, but in your environment the deployment names can be different and that is the name that you should enter in the code.\\\\n\\\\nNext we\\\\\\'re going to print the contents of assistant that we just created to confirm that creation was successful:\\\\n\\\\n```python\\\\nprint(assistant.model_dump_json(indent=2))\\\\n```\\\\n\\\\n```json\\\\n{\\\\n  \"id\": \"asst_7AZSrv5I3XzjUqWS40X5UgRr\",\\\\n  \"created_at\": 1705972454,\\\\n  \"description\": null,\\\\n  \"file_ids\": [],\\'}}, {\\'[doc1]\\': {\\'title\\': \\'assistants-python.md\\', \\'content\\': \\'can describe the assistant\\\\\\'s personality, tell it what it should and shouldn\\\\\\'t answer, and tell it how to format responses. You can also provide examples of the steps it should take when answering responses. |\\\\n| **Model** | This is where you set which model deployment name to use with your assistant. The retrieval tool requires `gpt-35-turbo (1106)` or `gpt-4 (1106-preview)` model. **Set this value to your deployment name, not the model name unless it is the same.** |\\\\n| **Code interpreter** | Code interpreter provides access to a sandboxed Python environment that can be used to allow the model to test and execute code. |\\\\n\\\\n### Tools\\\\n\\\\nAn individual assistant can access up to 128 tools including `code interpreter`, as well as any custom tools you create via [functions](../how-to/assistant-functions.md).\\\\n\\\\nCreate and run an assistant with the following:\\\\n\\\\n```python\\\\nimport os\\\\nimport time\\\\nimport json\\\\nfrom openai import AzureOpenAI\\\\n    \\\\nclient = AzureOpenAI(\\\\n    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \\\\n    api_version=\"2024-02-15-preview\",\\\\n    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\\\\n    )\\\\n\\\\n# Create an assistant\\\\nassistant = client.beta.assistants.create(\\\\n    name=\"Math Assist\",\\\\n    instructions=\"You are an AI assistant that can write code to help answer math questions.\",\\\\n    tools=[{\"type\": \"code_interpreter\"}],\\\\n    model=\"gpt-4-1106-preview\" #You must replace this value with the deployment name for your model.\\\\n)\\\\n\\\\n# Create a thread\\\\nthread = client.beta.threads.create()\\\\n\\\\n# Add a user question to the thread\\\\nmessage = client.beta.threads.messages.create(\\\\n    thread_id=thread.id,\\\\n    role=\"user\",\\\\n    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\\\\n)\\\\n\\\\n# Run the thread\\\\nrun = client.beta.threads.runs.create(\\\\n  thread_id=thread.id,\\\\n  assistant_id=assistant.id,\\\\n)\\\\n\\\\n# Retrieve the status of the run\\\\nrun = client.beta.threads.runs.retrieve(\\\\n  thread_id=thread.id,\\\\n  run_id=run.id\\\\n)\\\\n\\\\nstatus = run.status\\\\n\\\\n# Wait till the assistant has responded\\'}}, {\\'[doc2]\\': {\\'title\\': \\'assistants-python.md\\', \\'content\\': \\'\"assistant_id\": null,\\\\n      \"content\": [\\\\n        {\\\\n          \"text\": {\\\\n            \"annotations\": [],\\\\n            \"value\": \"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\\\\n          },\\\\n          \"type\": \"text\"\\\\n        }\\\\n      ],\\\\n      \"created_at\": 1705892751,\\\\n      \"file_ids\": [],\\\\n      \"metadata\": {},\\\\n      \"object\": \"thread.message\",\\\\n      \"role\": \"user\",\\\\n      \"run_id\": null,\\\\n      \"thread_id\": \"thread_hCOKdEZy1diZAAzwDudRqGRc\"\\\\n    }\\\\n  ],\\\\n  \"object\": \"list\",\\\\n  \"first_id\": \"msg_XOL8597uuV6zIEgaqZtI0KD3\",\\\\n  \"last_id\": \"msg_F25tb90W5xTPqSn4KgU4aMsb\",\\\\n  \"has_more\": false\\\\n}\\\\n```\\\\n\\\\n## Understanding your results\\\\n\\\\nIn this example we create an assistant with code interpreter enabled. When we ask the assistant a math question it translates the question into python code and executes the code in sandboxed environment in order to determine the answer to the question. The code the model creates and tests to arrive at an answer is:\\\\n\\\\n```python\\\\n    from sympy import symbols, Eq, solve  \\\\n      \\\\n    # Define the variable  \\\\n    x = symbols(\\\\\\'x\\\\\\')  \\\\n      \\\\n    # Define the equation  \\\\n    equation = Eq(3*x + 11, 14)  \\\\n      \\\\n    # Solve the equation  \\\\n    solution = solve(equation, x)  \\\\n    solution  \\\\n```\\\\n\\\\nIt is important to remember that while code interpreter gives the model the capability to respond to more complex queries by converting the questions into code and running that code iteratively in the Python sandbox until it reaches a solution, you still need to validate the response to confirm that the model correctly translated your question into a valid representation in code.\\\\n\\\\n<!--We walk through the process of creating assistants with code in much more depth in our [Azure OpenAI Assistants how-to guide](../how-to/assistant.md).-->\\\\n\\\\n## Clean up resources\\\\n\\\\nIf you want to clean up and remove an OpenAI resource, you can delete the resource or resource group. Deleting the resource group also deletes any other resources associated with it.\\'}}]}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documentation, metadata = get_contenxt(intent)\n",
    "documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f9ac52-d85b-4c33-bcdc-cbd22ce73ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'assistant.md',\n",
       "  'link': '<sup>[1](https://github.com/MicrosoftDocs/azure-docs/tree/main/articles/ai-service/openai/assistant.md)</sup>'},\n",
       " {'title': 'assistants-python.md',\n",
       "  'link': '<sup>[2](https://github.com/MicrosoftDocs/azure-docs/tree/main/articles/ai-service/openai/assistants-python.md)</sup>'},\n",
       " {'title': 'assistants-python.md',\n",
       "  'link': '<sup>[3](https://github.com/MicrosoftDocs/azure-docs/tree/main/articles/ai-service/openai/assistants-python.md)</sup>'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2124b20-f86d-4467-8bbb-aeb86c713cad",
   "metadata": {},
   "source": [
    "### generate answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ba10666-7488-4092-a893-3a5eb6df94d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(intent, documentation):\n",
    "    prompt = Template(reply_template, trim_blocks=True, keep_trailing_newline=True).render(\n",
    "        chat_history=chat_history,\n",
    "        documentation=documentation,\n",
    "        user_query=intent\n",
    "    )\n",
    "    \n",
    "    messages = parse_chat(prompt)\n",
    "    response = _chat_gpt(messages)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11160c06-d67d-4cec-b825-1ca94bbbf7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "output = generate_response(intent, documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "350946f4-3b96-4184-a5ee-88f820b840e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Assistant API in Python can be used to create an assistant with code interpreter enabled, allowing the model to respond to complex queries by converting questions into code and running that code iteratively in a Python sandbox until it reaches a solution[doc0][doc1][doc2]. Here's a sample code to create an assistant with code interpreter enabled:\n",
       "\n",
       "```python\n",
       "import os\n",
       "import time\n",
       "import json\n",
       "from openai import AzureOpenAI\n",
       "\n",
       "client = AzureOpenAI(\n",
       "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
       "    api_version=\"2024-02-15-preview\",\n",
       "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
       ")\n",
       "\n",
       "# Create an assistant\n",
       "assistant = client.beta.assistants.create(\n",
       "    name=\"Math Assist\",\n",
       "    instructions=\"You are an AI assistant that can write code to help answer math questions.\",\n",
       "    tools=[{\"type\": \"code_interpreter\"}],\n",
       "    model=\"gpt-4-1106-preview\" #You must replace this value with the deployment name for your model.\n",
       ")\n",
       "\n",
       "# Create a thread\n",
       "thread = client.beta.threads.create()\n",
       "\n",
       "# Add a user question to the thread\n",
       "message = client.beta.threads.messages.create(\n",
       "    thread_id=thread.id,\n",
       "    role=\"user\",\n",
       "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
       ")\n",
       "\n",
       "# Run the thread\n",
       "run = client.beta.threads.runs.create(\n",
       "  thread_id=thread.id,\n",
       "  assistant_id=assistant.id,\n",
       ")\n",
       "\n",
       "# Retrieve the status of the run\n",
       "run = client.beta.threads.runs.retrieve(\n",
       "  thread_id=thread.id,\n",
       "  run_id=run.id\n",
       ")\n",
       "\n",
       "status = run.status\n",
       "\n",
       "# Wait till the assistant has responded\n",
       "```\n",
       "This code demonstrates the creation of an assistant with code interpreter enabled and the process of running a thread to interact with the assistant[doc1][doc2]. Remember to replace the `model` value with the deployment name for your model[doc0][doc1]."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7337bfa8-75b8-4517-9233-baf42027dbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant api sample code in rest api\n"
     ]
    }
   ],
   "source": [
    "query = \"assistant api sample code in rest api\"\n",
    "intent, raw_intent = get_search_intent(query, intent_history)\n",
    "intent_history.append(intent)\n",
    "\n",
    "print(intent)\n",
    "documentation = get_contenxt(intent)\n",
    "\n",
    "output = generate_response(intent, documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edcbdee3-93f8-4a7b-83ea-f683b375e18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample code for using the Assistant API in REST API can be found in the following snippet:\n",
      "\n",
      "```console\n",
      "curl https://YOUR_RESOURCE_NAME.openai.azure.com/openai/assistants?api-version=2024-02-15-preview \\\n",
      "  -H \"api-key: $AZURE_OPENAI_KEY\" \\\n",
      "  -H \"Content-Type: application/json\" \\\n",
      "  -d '{\n",
      "    \"instructions\": \"You are an AI assistant that can write code to help answer math questions.\",\n",
      "    \"name\": \"Math Assist\",\n",
      "    \"tools\": [{\"type\": \"code_interpreter\"}],\n",
      "    \"model\": \"gpt-4-1106-preview\"\n",
      "  }'\n",
      "```\n",
      "This code creates an assistant with specific instructions, name, tools, and model parameters[doc0][doc2]. You can find more details and examples in the Azure OpenAI Assistants REST API documentation[1](https://github.com/MicrosoftDocs/azure-docs/tree/main/articles/ai-service/openai/assistants-rest.md).\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a53cedf-7370-405f-b31d-1f2c43970d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
