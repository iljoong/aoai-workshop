{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a200b06-1d83-4065-a6bf-b4a4cfd08b46",
   "metadata": {},
   "source": [
    "# Document Retrieve - Chunking (Manual)\n",
    "\n",
    "Chunking document manually using LangChain\n",
    "\n",
    "- Chunking\n",
    "    - md & text split of md formated texet\n",
    "- Data analysis (Token size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513539f2-8273-46ea-8db2-f874f637faea",
   "metadata": {},
   "source": [
    "## Doucment prep\n",
    "\n",
    "Azure OpenAI documents (MD formatted)\n",
    "- https://github.com/MicrosoftDocs/azure-docs/tree/main/articles/ai-services/openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5595c1be-0c95-43bd-b530-caa6136cf7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def token_size(text):\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca47b5a6-af7b-4894-ad97-58ddc57bb16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188c3e35-a678-40ab-abb1-b7d891e12928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_between_markers(text, start_marker, end_marker):\n",
    "    # Find the start and end positions of the markers\n",
    "    start_pos = text.find(start_marker)\n",
    "    end_pos = text.find(end_marker, start_pos + len(start_marker))\n",
    "    \n",
    "    # Remove the content between the markers\n",
    "    if start_pos != -1 and end_pos != -1:\n",
    "        return text[:start_pos] + text[end_pos + len(end_marker):]\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "124ff536-c4d0-4139-a3d7-bb3db209198b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>size</th>\n",
       "      <th>token_size</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>content-filters.md</td>\n",
       "      <td>13289</td>\n",
       "      <td>2691</td>\n",
       "      <td>How to use content filters (preview) with Azur...</td>\n",
       "      <td># How to configure content filters with Azure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dotnet-new-application.md</td>\n",
       "      <td>709</td>\n",
       "      <td>177</td>\n",
       "      <td>dotnet-new-application.md</td>\n",
       "      <td>### Create a new .NET Core application\\n\\nIn a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fine-tuning-python.md</td>\n",
       "      <td>33086</td>\n",
       "      <td>7734</td>\n",
       "      <td>Customize a model with Azure OpenAI Service an...</td>\n",
       "      <td>## Prerequisites\\n\\n- Read the [When to use Az...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>use-your-data-dotnet.md</td>\n",
       "      <td>5775</td>\n",
       "      <td>1210</td>\n",
       "      <td>use-your-data-dotnet.md</td>\n",
       "      <td>[!INCLUDE [Set up required variables](./use-yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text-to-speech-rest.md</td>\n",
       "      <td>1202</td>\n",
       "      <td>293</td>\n",
       "      <td>text-to-speech-rest.md</td>\n",
       "      <td>## REST API\\n\\nIn a bash shell, run the follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>gpt-v-quickstart.md</td>\n",
       "      <td>654</td>\n",
       "      <td>182</td>\n",
       "      <td>Quickstart: Use GPT-4 Turbo with Vision on you...</td>\n",
       "      <td># Quickstart: Use images in your AI chats\\n\\n:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>use-your-data-powershell.md</td>\n",
       "      <td>4169</td>\n",
       "      <td>971</td>\n",
       "      <td>use-your-data-powershell.md</td>\n",
       "      <td>[!INCLUDE [Set up required variables](./use-yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>use-your-data-python.md</td>\n",
       "      <td>4593</td>\n",
       "      <td>1084</td>\n",
       "      <td>use-your-data-python.md</td>\n",
       "      <td>[!INCLUDE [Set up required variables](./use-yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>use-your-image-data.md</td>\n",
       "      <td>13966</td>\n",
       "      <td>3096</td>\n",
       "      <td>Use your image data with Azure OpenAI Service ...</td>\n",
       "      <td># Azure OpenAI on your data with images using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>use-your-data-go.md</td>\n",
       "      <td>4892</td>\n",
       "      <td>1228</td>\n",
       "      <td>use-your-data-go.md</td>\n",
       "      <td>[!INCLUDE [Set up required variables](./use-yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file_name   size token_size  \\\n",
       "0             content-filters.md  13289       2691   \n",
       "1      dotnet-new-application.md    709        177   \n",
       "2          fine-tuning-python.md  33086       7734   \n",
       "3        use-your-data-dotnet.md   5775       1210   \n",
       "4         text-to-speech-rest.md   1202        293   \n",
       "..                           ...    ...        ...   \n",
       "133          gpt-v-quickstart.md    654        182   \n",
       "134  use-your-data-powershell.md   4169        971   \n",
       "135      use-your-data-python.md   4593       1084   \n",
       "136       use-your-image-data.md  13966       3096   \n",
       "137          use-your-data-go.md   4892       1228   \n",
       "\n",
       "                                                 title  \\\n",
       "0    How to use content filters (preview) with Azur...   \n",
       "1                            dotnet-new-application.md   \n",
       "2    Customize a model with Azure OpenAI Service an...   \n",
       "3                              use-your-data-dotnet.md   \n",
       "4                               text-to-speech-rest.md   \n",
       "..                                                 ...   \n",
       "133  Quickstart: Use GPT-4 Turbo with Vision on you...   \n",
       "134                        use-your-data-powershell.md   \n",
       "135                            use-your-data-python.md   \n",
       "136  Use your image data with Azure OpenAI Service ...   \n",
       "137                                use-your-data-go.md   \n",
       "\n",
       "                                               content  \n",
       "0    # How to configure content filters with Azure ...  \n",
       "1    ### Create a new .NET Core application\\n\\nIn a...  \n",
       "2    ## Prerequisites\\n\\n- Read the [When to use Az...  \n",
       "3    [!INCLUDE [Set up required variables](./use-yo...  \n",
       "4    ## REST API\\n\\nIn a bash shell, run the follow...  \n",
       "..                                                 ...  \n",
       "133  # Quickstart: Use images in your AI chats\\n\\n:...  \n",
       "134  [!INCLUDE [Set up required variables](./use-yo...  \n",
       "135  [!INCLUDE [Set up required variables](./use-yo...  \n",
       "136  # Azure OpenAI on your data with images using ...  \n",
       "137  [!INCLUDE [Set up required variables](./use-yo...  \n",
       "\n",
       "[138 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty DataFrame with specific column names\n",
    "df = pd.DataFrame(columns=['file_name', 'size', 'token_size', 'title', 'content'])\n",
    "\n",
    "for md in os.listdir(\"./docs\"):\n",
    "    if not os.path.isdir(md):\n",
    "        with open(f'./docs/{md}', \"r\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "    pattern = r\"title:\\s*(.*)\"\n",
    "    matches = re.search(pattern, text)\n",
    "\n",
    "    # get title from header\n",
    "    title = \"\"\n",
    "    if matches:\n",
    "        title = matches.group(1)\n",
    "        title = title.replace(\"'\", \"\")\n",
    "    else:\n",
    "        title = md\n",
    "\n",
    "    # clean header\n",
    "    text = remove_between_markers(text, \"---\", \"---\\n\\n\")\n",
    "    \n",
    "    new_row = {'file_name': md, 'size': len(text), 'token_size': token_size(text), 'title':  title, 'content': text}\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1df8a97-6c30-4750-bd0d-5531e539519b",
   "metadata": {},
   "source": [
    "df[df['title'] == \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b5749-9bf7-48ad-9ba7-3f1a6d0e8dfb",
   "metadata": {},
   "source": [
    "## Chunking Comparison\n",
    "\n",
    "- https://github.com/Azure/azure-search-vector-samples/blob/main/demo-python/code/data-chunking/langchain-data-chunking-example.ipynb\n",
    "- https://python.langchain.com/docs/modules/data_connection/document_loaders/file_directory#auto-detect-file-encodings-with-textloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f8e999e-b751-4d7d-b6d7-8895bc28c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter\n",
    "\n",
    "def get_encoding_name(model=\"gpt-4o\"):\n",
    "    return tiktoken.encoding_for_model(model).name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b703f51a-5fe7-4bf1-a821-0276f0146e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Getting started with Azure OpenAI Assistants (Preview)\\n\\nAzure OpenAI Assistants (Preview) allows you to create AI assistants tailored to your needs through custom instructions and augmented by advanced tools like code interpreter, and custom functions. In this article we\\'ll provide an in-depth walkthrough of getting started with the Assistants API.\\n\\n## Assistants support\\n\\n### Region and model support\\n\\nThe [models page](../concepts/models.md#assistants-preview) contains the most up-to-date information on regions/models where Assistants are currently supported.\\n\\n### API Version\\n\\n- `2024-02-15-preview`\\n\\n### Supported file types\\n\\n|File format|MIME Type|Code Interpreter |\\n|---|---|---|\\n|.c| text/x-c |✅|\\n|.cpp|text/x-c++ |✅|\\n|.csv|application/csv|✅|\\n|.docx|application/vnd.openxmlformats-officedocument.wordprocessingml.document|✅|\\n|.html|text/html|✅|\\n|.java|text/x-java|✅|\\n|.json|application/json|✅|\\n|.md|text/markdown| ✅ |\\n|.pdf|application/pdf|✅|\\n|.php|text/x-php|✅|\\n|.pptx|application/vnd.openxmlformats-officedocument.presentationml.presentation|✅|\\n|.py|text/x-python|✅|\\n|.py|text/x-script.python|✅|\\n|.rb|text/x-ruby|✅|\\n|.tex|text/x-tex|✅|\\n|.txt|text/plain|✅|\\n|.css|text/css|✅|\\n|.jpeg|image/jpeg|✅|\\n|.jpg|image/jpeg|✅|\\n|.js|text/javascript|✅|\\n|.gif|image/gif|✅|\\n|.png|image/png|✅|\\n|.tar|application/x-tar|✅|\\n|.ts|application/typescript|✅|\\n|.xlsx|application/vnd.openxmlformats-officedocument.spreadsheetml.sheet|✅|\\n|.xml|application/xml or \"text/xml\"|✅|\\n|.zip|application/zip|✅|\\n\\n### Tools\\n\\nAn individual assistant can access up to 128 tools including `code interpreter`, but you can also define your own custom tools via [functions](./assistant-functions.md).\\n\\n### Files\\n\\nFiles can be uploaded via Studio, or programmatically. The `file_ids` parameter is required to give tools like `code_interpreter` access to files. When using the File upload endpoint, you must have the `purpose` set to assistants to be used with the Assistants API.\\n\\n## Assistants playground\\n\\nWe provide a walkthrough of the Assistants playground in our [quickstart guide](../assistants-quickstart.md). This provides a no-code environment to test out the capabilities of assistants.\\n\\n## Assistants components\\n\\n| **Component** | **Description** |\\n|---|---|\\n| **Assistant** | Custom AI that uses Azure OpenAI models in conjunction with tools. |\\n|**Thread** | A conversation session between an Assistant and a user. Threads store Messages and automatically handle truncation to fit content into a model’s context.|\\n| **Message** | A message created by an Assistant or a user. Messages can include text, images, and other files. Messages are stored as a list on the Thread. |\\n|**Run** | Activation of an Assistant to begin running based on the contents of the Thread. The Assistant uses its configuration and the Thread’s Messages to perform tasks by calling models and tools. As part of a Run, the Assistant appends Messages to the Thread.|\\n|**Run Step** | A detailed list of steps the Assistant took as part of a Run. An Assistant can call tools or create Messages during it’s run. Examining Run Steps allows you to understand how the Assistant is getting to its final results. |\\n\\n## Setting up your first Assistant\\n\\n### Create an assistant\\n\\nFor this example we\\'ll create an assistant that writes code to generate visualizations using the capabilities of the `code_interpreter` tool. The examples below are intended to be run sequentially in an environment like [Jupyter Notebooks](https://jupyter.org/).\\n\\n```Python\\nimport os\\nimport json\\nfrom openai import AzureOpenAI\\n    \\nclient = AzureOpenAI(\\n    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \\n    api_version=\"2024-02-15-preview\",\\n    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\\n    )\\n\\n# Create an assistant\\nassistant = client.beta.assistants.create(\\n    name=\"Data Visualization\",\\n    instructions=f\"You are a helpful AI assistant who makes interesting visualizations based on data.\" \\n    f\"You have access to a sandboxed environment for writing and testing code.\"\\n    f\"When you are asked to create a visualization you should follow these steps:\"\\n    f\"1. Write the code.\"\\n    f\"2. Anytime you write new code display a preview of the code to show your work.\"\\n    f\"3. Run the code to confirm that it runs.\"\\n    f\"4. If the code is successful display the visualization.\"\\n    f\"5. If the code is unsuccessful display the error message and try to revise the code and rerun going through the steps from above again.\",\\n    tools=[{\"type\": \"code_interpreter\"}],\\n    model=\"gpt-4-1106-preview\" #You must replace this value with the deployment name for your model.\\n)\\n\\n```\\n\\nThere are a few details you should note from the configuration above:\\n\\n- We enable this assistant to access code interpreter with the line ` tools=[{\"type\": \"code_interpreter\"}],`. This gives the model access to a sand-boxed python environment to run and execute code to help formulating responses to a user\\'s question.\\n- In the instructions we remind the model that it can execute code. Sometimes the model needs help guiding it towards the right tool to solve a given query. If you know, you want to use a particular library to generate a certain response that you know is part of code interpreter it can help to provide guidance by saying something like \"Use Matplotlib to do x.\"\\n- Since this is Azure OpenAI the value you enter for `model=` **must match the deployment name**. By convention our docs will often use a deployment name that happens to match the model name to indicate which model was used when testing a given example, but in your environment the deployment names can be different and that is the name that you should enter in the code.\\n\\nNext we\\'re going to print the contents of assistant that we just created to confirm that creation was successful:\\n\\n```python\\nprint(assistant.model_dump_json(indent=2))\\n```\\n\\n```json\\n{\\n  \"id\": \"asst_7AZSrv5I3XzjUqWS40X5UgRr\",\\n  \"created_at\": 1705972454,\\n  \"description\": null,\\n  \"file_ids\": [],\\n  \"instructions\": \"You are a helpful AI assistant who makes interesting visualizations based on data.You have access to a sandboxed environment for writing and testing code.When you are asked to create a visualization you should follow these steps:1. Write the code.2. Anytime you write new code display a preview of the code to show your work.3. Run the code to confirm that it runs.4. If the code is successful display the visualization.5. If the code is unsuccessful display the error message and try to revise the code and rerun going through the steps from above again.\",\\n  \"metadata\": {},\\n  \"model\": \"gpt-4-1106-preview\",\\n  \"name\": \"Data Visualization\",\\n  \"object\": \"assistant\",\\n  \"tools\": [\\n    {\\n      \"type\": \"code_interpreter\"\\n    }\\n  ]\\n}\\n```\\n\\n### Create a thread\\n\\nNow let\\'s create a thread\\n\\n```python\\n# Create a thread\\nthread = client.beta.threads.create()\\nprint(thread)\\n```\\n\\n```output\\nThread(id=\\'thread_6bunpoBRZwNhovwzYo7fhNVd\\', created_at=1705972465, metadata={}, object=\\'thread\\')\\n```\\n\\nA thread is essentially the record of the conversation session between the assistant and the user. It\\'s similar to the messages array/list in a typical chat completions API call. One of the key differences, is unlike a chat completions messages array, you don\\'t need to track tokens with each call to make sure that you\\'re remaining below the context length of the model. Threads abstract away this management detail and will compress the thread history as needed in order to allow the conversation to continue. The ability for threads to accomplish this with larger conversations is enhanced when using the latest models, which have larger context lengths as well as support for the latest features.\\n\\nNext create the first user question to add to the thread\\n\\n```python\\n# Add a user question to the thread\\nmessage = client.beta.threads.messages.create(\\n    thread_id=thread.id,\\n    role=\"user\",\\n    content=\"Create a visualization of a sinewave\"\\n)\\n```\\n\\n### List thread messages\\n\\n```python\\nthread_messages = client.beta.threads.messages.list(thread.id)\\nprint(thread_messages.model_dump_json(indent=2))\\n```\\n\\n```json\\n{\\n  \"data\": [\\n    {\\n      \"id\": \"msg_JnkmWPo805Ft8NQ0gZF6vA2W\",\\n      \"assistant_id\": null,\\n      \"content\": [\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Create a visualization of a sinewave\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705972476,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"user\",\\n      \"run_id\": null,\\n      \"thread_id\": \"thread_6bunpoBRZwNhovwzYo7fhNVd\"\\n    }\\n  ],\\n  \"object\": \"list\",\\n  \"first_id\": \"msg_JnkmWPo805Ft8NQ0gZF6vA2W\",\\n  \"last_id\": \"msg_JnkmWPo805Ft8NQ0gZF6vA2W\",\\n  \"has_more\": false\\n}\\n```\\n\\n### Run thread\\n\\n```python\\nrun = client.beta.threads.runs.create(\\n  thread_id=thread.id,\\n  assistant_id=assistant.id,\\n  #instructions=\"New instructions\" #You can optionally provide new instructions but these will override the default instructions\\n)\\n```\\n\\nWe could also pass an `instructions` parameter here, but this would override the existing instructions that we have already provided for the assistant.\\n\\n### Retrieve thread status\\n\\n```python\\n# Retrieve the status of the run\\nrun = client.beta.threads.runs.retrieve(\\n  thread_id=thread.id,\\n  run_id=run.id\\n)\\n\\nstatus = run.status\\nprint(status)\\n```\\n\\n```output\\ncompleted\\n```\\n\\nDepending on the complexity of the query you run, the thread could take longer to execute. In that case you can create a loop to monitor the [run status](#run-status-definitions) of the thread with code like the example below:\\n\\n```python\\nimport time\\nfrom IPython.display import clear_output\\n\\nstart_time = time.time()\\n\\nstatus = run.status\\n\\nwhile status not in [\"completed\", \"cancelled\", \"expired\", \"failed\"]:\\n    time.sleep(5)\\n    run = client.beta.threads.runs.retrieve(thread_id=thread.id,run_id=run.id)\\n    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\\n    status = run.status\\n    print(f\\'Status: {status}\\')\\n    clear_output(wait=True)\\n\\nmessages = client.beta.threads.messages.list(\\n  thread_id=thread.id\\n) \\n\\nprint(f\\'Status: {status}\\')\\nprint(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\\nprint(messages.model_dump_json(indent=2))\\n```\\n\\nWhen a Run is `in_progress` or in other nonterminal states the thread is locked. When a thread is locked new messages can\\'t be added, and new runs can\\'t be created.\\n\\n### List thread messages post run\\n\\nOnce the run status indicates successful completion, you can list the contents of the thread again to retrieve the model\\'s and any tools response:\\n\\n```python\\nmessages = client.beta.threads.messages.list(\\n  thread_id=thread.id\\n)\\n\\nprint(messages.model_dump_json(indent=2))\\n```\\n\\n```json\\n{\\n  \"data\": [\\n    {\\n      \"id\": \"msg_M5pz73YFsJPNBbWvtVs5ZY3U\",\\n      \"assistant_id\": \"asst_eHwhP4Xnad0bZdJrjHO2hfB4\",\\n      \"content\": [\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Is there anything else you would like to visualize or any additional features you\\'d like to add to the sine wave plot?\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705967782,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"assistant\",\\n      \"run_id\": \"run_AGQHJrrfV3eM0eI9T3arKgYY\",\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    },\\n    {\\n      \"id\": \"msg_oJbUanImBRpRran5HSa4Duy4\",\\n      \"assistant_id\": \"asst_eHwhP4Xnad0bZdJrjHO2hfB4\",\\n      \"content\": [\\n        {\\n          \"image_file\": {\\n            \"file_id\": \"assistant-1YGVTvNzc2JXajI5JU9F0HMD\"\\n          },\\n          \"type\": \"image_file\"\\n        },\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Here is the visualization of a sine wave: \\\\n\\\\nThe wave is plotted using values from 0 to \\\\\\\\( 4\\\\\\\\pi \\\\\\\\) on the x-axis, and the corresponding sine values on the y-axis. I\\'ve also added grid lines for easier reading of the plot.\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705967044,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"assistant\",\\n      \"run_id\": \"run_8PsweDFn6gftUd91H87K0Yts\",\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    },\\n    {\\n      \"id\": \"msg_Pu3eHjM10XIBkwqh7IhnKKdG\",\\n      \"assistant_id\": null,\\n      \"content\": [\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Create a visualization of a sinewave\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705966634,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"user\",\\n      \"run_id\": null,\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    }\\n  ],\\n  \"object\": \"list\",\\n  \"first_id\": \"msg_M5pz73YFsJPNBbWvtVs5ZY3U\",\\n  \"last_id\": \"msg_Pu3eHjM10XIBkwqh7IhnKKdG\",\\n  \"has_more\": false\\n}\\n```\\n\\n### Retrieve file ID\\n\\nWe had requested that the model generate an image of a sine wave. In order to download the image, we first need to retrieve the images file ID.\\n\\n```python\\ndata = json.loads(messages.model_dump_json(indent=2))  # Load JSON data into a Python object\\nimage_file_id = data[\\'data\\'][1][\\'content\\'][0][\\'image_file\\'][\\'file_id\\']\\n\\nprint(image_file_id)  # Outputs: assistant-1YGVTvNzc2JXajI5JU9F0HMD\\n```\\n\\n### Download image\\n\\n```python\\ncontent = client.files.content(image_file_id)\\n\\nimage= content.write_to_file(\"sinewave.png\")\\n```\\n\\nOpen the image locally once it\\'s downloaded:\\n\\n```python\\nfrom PIL import Image\\n\\n# Display the image in the default image viewer\\nimage = Image.open(\"sinewave.png\")\\nimage.show()\\n```\\n\\n:::image type=\"content\" source=\"../media/how-to/assistants/sine-wave.png\" alt-text=\"Screenshot of code interpreter generated sinewave.\" lightbox=\"../media/how-to/assistants/sine-wave.png\":::\\n\\n### Ask a follow-up question on the thread\\n\\nSince the assistant didn\\'t quite follow our instructions and include the code that was run in the text portion of its response lets explicitly ask for that information.\\n\\n```python\\n# Add a new user question to the thread\\nmessage = client.beta.threads.messages.create(\\n    thread_id=thread.id,\\n    role=\"user\",\\n    content=\"Show me the code you used to generate the sinewave\"\\n)\\n```\\n\\nAgain we\\'ll need to run and retrieve the status of the thread:\\n\\n```python\\nrun = client.beta.threads.runs.create(\\n  thread_id=thread.id,\\n  assistant_id=assistant.id,\\n  #instructions=\"New instructions\" #You can optionally provide new instructions  but these will override the default instructions\\n)\\n\\n# Retrieve the status of the run\\nrun = client.beta.threads.runs.retrieve(\\n  thread_id=thread.id,\\n  run_id=run.id\\n)\\n\\nstatus = run.status\\nprint(status)\\n\\n```\\n\\n```output\\ncompleted\\n```\\n\\nOnce the run status reaches completed, we\\'ll list the messages in the thread again which should now include the response to our latest question.\\n\\n```python\\nmessages = client.beta.threads.messages.list(\\n  thread_id=thread.id\\n)\\n\\nprint(messages.model_dump_json(indent=2))\\n```\\n\\n```json\\n{\\n  \"data\": [\\n    {\\n      \"id\": \"msg_oaF1PUeozAvj3KrNnbKSy4LQ\",\\n      \"assistant_id\": \"asst_eHwhP4Xnad0bZdJrjHO2hfB4\",\\n      \"content\": [\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Certainly, here is the code I used to generate the sine wave visualization:\\\\n\\\\n```python\\\\nimport numpy as np\\\\nimport matplotlib.pyplot as plt\\\\n\\\\n# Generating data for the sinewave\\\\nx = np.linspace(0, 4 * np.pi, 1000)  # Generate values from 0 to 4*pi\\\\ny = np.sin(x)  # Compute the sine of these values\\\\n\\\\n# Plotting the sine wave\\\\nplt.plot(x, y)\\\\nplt.title(\\'Sine Wave\\')\\\\nplt.xlabel(\\'x\\')\\\\nplt.ylabel(\\'sin(x)\\')\\\\nplt.grid(True)\\\\nplt.show()\\\\n```\\\\n\\\\nThis code snippet uses `numpy` to generate an array of x values and then computes the sine for each x value. It then uses `matplotlib` to plot these values and display the resulting graph.\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705969710,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"assistant\",\\n      \"run_id\": \"run_oDS3fH7NorCUVwROTZejKcZN\",\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    },\\n    {\\n      \"id\": \"msg_moYE3aNwFYuRq2aXpxpt2Wb0\",\\n      \"assistant_id\": null,\\n      \"content\": [\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Show me the code you used to generate the sinewave\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705969678,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"user\",\\n      \"run_id\": null,\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    },\\n    {\\n      \"id\": \"msg_M5pz73YFsJPNBbWvtVs5ZY3U\",\\n      \"assistant_id\": \"asst_eHwhP4Xnad0bZdJrjHO2hfB4\",\\n      \"content\": [\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Is there anything else you would like to visualize or any additional features you\\'d like to add to the sine wave plot?\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705967782,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"assistant\",\\n      \"run_id\": \"run_AGQHJrrfV3eM0eI9T3arKgYY\",\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    },\\n    {\\n      \"id\": \"msg_oJbUanImBRpRran5HSa4Duy4\",\\n      \"assistant_id\": \"asst_eHwhP4Xnad0bZdJrjHO2hfB4\",\\n      \"content\": [\\n        {\\n          \"image_file\": {\\n            \"file_id\": \"assistant-1YGVTvNzc2JXajI5JU9F0HMD\"\\n          },\\n          \"type\": \"image_file\"\\n        },\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Here is the visualization of a sine wave: \\\\n\\\\nThe wave is plotted using values from 0 to \\\\\\\\( 4\\\\\\\\pi \\\\\\\\) on the x-axis, and the corresponding sine values on the y-axis. I\\'ve also added grid lines for easier reading of the plot.\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705967044,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"assistant\",\\n      \"run_id\": \"run_8PsweDFn6gftUd91H87K0Yts\",\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    },\\n    {\\n      \"id\": \"msg_Pu3eHjM10XIBkwqh7IhnKKdG\",\\n      \"assistant_id\": null,\\n      \"content\": [\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Create a visualization of a sinewave\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705966634,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"user\",\\n      \"run_id\": null,\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    }\\n  ],\\n  \"object\": \"list\",\\n  \"first_id\": \"msg_oaF1PUeozAvj3KrNnbKSy4LQ\",\\n  \"last_id\": \"msg_Pu3eHjM10XIBkwqh7IhnKKdG\",\\n  \"has_more\": false\\n}\\n```\\n\\nTo extract only the response to our latest question:\\n\\n```python\\ndata = json.loads(messages.model_dump_json(indent=2))\\ncode = data[\\'data\\'][0][\\'content\\'][0][\\'text\\'][\\'value\\']\\nprint(code)\\n```\\n\\n*Certainly, here is the code I used to generate the sine wave visualization:*\\n\\n```python\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Generating data for the sinewave\\nx = np.linspace(0, 4 * np.pi, 1000)  # Generate values from 0 to 4*pi\\ny = np.sin(x)  # Compute the sine of these values\\n\\n# Plotting the sine wave\\nplt.plot(x, y)\\nplt.title(\\'Sine Wave\\')\\nplt.xlabel(\\'x\\')\\nplt.ylabel(\\'sin(x)\\')\\nplt.grid(True)\\nplt.show()\\n```\\n\\n### Dark mode\\n\\nLet\\'s add one last question to the thread to see if code interpreter can swap the chart to dark mode for us.\\n\\n```python\\n# Add a user question to the thread\\nmessage = client.beta.threads.messages.create(\\n    thread_id=thread.id,\\n    role=\"user\",\\n    content=\"I prefer visualizations in darkmode can you change the colors to make a darkmode version of this visualization.\"\\n)\\n\\n# Run the thread\\nrun = client.beta.threads.runs.create(\\n  thread_id=thread.id,\\n  assistant_id=assistant.id,\\n)\\n\\n# Retrieve the status of the run\\nrun = client.beta.threads.runs.retrieve(\\n  thread_id=thread.id,\\n  run_id=run.id\\n)\\n\\nstatus = run.status\\nprint(status)\\n```\\n\\n```output\\ncompleted\\n```\\n\\n```python\\nmessages = client.beta.threads.messages.list(\\n  thread_id=thread.id\\n)\\n\\nprint(messages.model_dump_json(indent=2))\\n```\\n\\n```json\\n{\\n  \"data\": [\\n    {\\n      \"id\": \"msg_KKzOHCArWGvGpuPo0pVZTHgV\",\\n      \"assistant_id\": \"asst_eHwhP4Xnad0bZdJrjHO2hfB4\",\\n      \"content\": [\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"You\\'re viewing the dark mode version of the sine wave visualization in the image above. The plot is set against a dark background with a cyan colored sine wave for better contrast and visibility. If there\\'s anything else you\\'d like to adjust or any other assistance you need, feel free to let me know!\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705971199,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"assistant\",\\n      \"run_id\": \"run_izZFyTVB1AlFM1VVMItggRn4\",\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    },\\n    {\\n      \"id\": \"msg_30pXFVYNgP38qNEMS4Zbozfk\",\\n      \"assistant_id\": null,\\n      \"content\": [\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"I prefer visualizations in darkmode can you change the colors to make a darkmode version of this visualization.\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705971194,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"user\",\\n      \"run_id\": null,\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    },\\n    {\\n      \"id\": \"msg_3j31M0PaJLqO612HLKVsRhlw\",\\n      \"assistant_id\": \"asst_eHwhP4Xnad0bZdJrjHO2hfB4\",\\n      \"content\": [\\n        {\\n          \"image_file\": {\\n            \"file_id\": \"assistant-kfqzMAKN1KivQXaEJuU0u9YS\"\\n          },\\n          \"type\": \"image_file\"\\n        },\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Here is the dark mode version of the sine wave visualization. I\\'ve used the \\'dark_background\\' style in Matplotlib and chosen a cyan color for the plot line to ensure it stands out against the dark background.\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705971123,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"assistant\",\\n      \"run_id\": \"run_B91erEPWro4bZIfryQeIDDlx\",\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    },\\n    {\\n      \"id\": \"msg_FgDZhBvvM1CLTTFXwgeJLdua\",\\n      \"assistant_id\": null,\\n      \"content\": [\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"I prefer visualizations in darkmode can you change the colors to make a darkmode version of this visualization.\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705971052,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"user\",\\n      \"run_id\": null,\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    },\\n    {\\n      \"id\": \"msg_oaF1PUeozAvj3KrNnbKSy4LQ\",\\n      \"assistant_id\": \"asst_eHwhP4Xnad0bZdJrjHO2hfB4\",\\n      \"content\": [\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Certainly, here is the code I used to generate the sine wave visualization:\\\\n\\\\n```python\\\\nimport numpy as np\\\\nimport matplotlib.pyplot as plt\\\\n\\\\n# Generating data for the sinewave\\\\nx = np.linspace(0, 4 * np.pi, 1000)  # Generate values from 0 to 4*pi\\\\ny = np.sin(x)  # Compute the sine of these values\\\\n\\\\n# Plotting the sine wave\\\\nplt.plot(x, y)\\\\nplt.title(\\'Sine Wave\\')\\\\nplt.xlabel(\\'x\\')\\\\nplt.ylabel(\\'sin(x)\\')\\\\nplt.grid(True)\\\\nplt.show()\\\\n```\\\\n\\\\nThis code snippet uses `numpy` to generate an array of x values and then computes the sine for each x value. It then uses `matplotlib` to plot these values and display the resulting graph.\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705969710,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"assistant\",\\n      \"run_id\": \"run_oDS3fH7NorCUVwROTZejKcZN\",\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    },\\n    {\\n      \"id\": \"msg_moYE3aNwFYuRq2aXpxpt2Wb0\",\\n      \"assistant_id\": null,\\n      \"content\": [\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Show me the code you used to generate the sinewave\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705969678,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"user\",\\n      \"run_id\": null,\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    },\\n    {\\n      \"id\": \"msg_M5pz73YFsJPNBbWvtVs5ZY3U\",\\n      \"assistant_id\": \"asst_eHwhP4Xnad0bZdJrjHO2hfB4\",\\n      \"content\": [\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Is there anything else you would like to visualize or any additional features you\\'d like to add to the sine wave plot?\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705967782,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"assistant\",\\n      \"run_id\": \"run_AGQHJrrfV3eM0eI9T3arKgYY\",\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    },\\n    {\\n      \"id\": \"msg_oJbUanImBRpRran5HSa4Duy4\",\\n      \"assistant_id\": \"asst_eHwhP4Xnad0bZdJrjHO2hfB4\",\\n      \"content\": [\\n        {\\n          \"image_file\": {\\n            \"file_id\": \"assistant-1YGVTvNzc2JXajI5JU9F0HMD\"\\n          },\\n          \"type\": \"image_file\"\\n        },\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Here is the visualization of a sine wave: \\\\n\\\\nThe wave is plotted using values from 0 to \\\\\\\\( 4\\\\\\\\pi \\\\\\\\) on the x-axis, and the corresponding sine values on the y-axis. I\\'ve also added grid lines for easier reading of the plot.\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705967044,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"assistant\",\\n      \"run_id\": \"run_8PsweDFn6gftUd91H87K0Yts\",\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    },\\n    {\\n      \"id\": \"msg_Pu3eHjM10XIBkwqh7IhnKKdG\",\\n      \"assistant_id\": null,\\n      \"content\": [\\n        {\\n          \"text\": {\\n            \"annotations\": [],\\n            \"value\": \"Create a visualization of a sinewave\"\\n          },\\n          \"type\": \"text\"\\n        }\\n      ],\\n      \"created_at\": 1705966634,\\n      \"file_ids\": [],\\n      \"metadata\": {},\\n      \"object\": \"thread.message\",\\n      \"role\": \"user\",\\n      \"run_id\": null,\\n      \"thread_id\": \"thread_ow1Yv29ptyVtv7ixbiKZRrHd\"\\n    }\\n  ],\\n  \"object\": \"list\",\\n  \"first_id\": \"msg_KKzOHCArWGvGpuPo0pVZTHgV\",\\n  \"last_id\": \"msg_Pu3eHjM10XIBkwqh7IhnKKdG\",\\n  \"has_more\": false\\n}\\n```\\n\\nExtract the new image file ID and download and display the image:\\n\\n```python\\ndata = json.loads(messages.model_dump_json(indent=2))  # Load JSON data into a Python object\\nimage_file_id = data[\\'data\\'][0][\\'content\\'][0][\\'image_file\\'][\\'file_id\\'] # index numbers can vary if you have had a different conversation over the course of the thread.\\n\\nprint(image_file_id)\\n\\ncontent = client.files.content(image_file_id)\\nimage= content.write_to_file(\"dark_sine.png\")\\n\\n# Display the image in the default image viewer\\nimage = Image.open(\"dark_sine.png\")\\nimage.show()\\n```\\n\\n:::image type=\"content\" source=\"../media/how-to/assistants/dark-mode.png\" alt-text=\"Screenshot of code interpreter generated sinewave in darkmode.\" lightbox=\"../media/how-to/assistants/dark-mode.png\":::\\n\\n## Additional reference\\n\\n### Run status definitions\\n\\n|**Status**| **Definition**|\\n|------|--------------|\\n|`queued`| When Runs are first created or when you complete the required_action, they are moved to a queued status. They should almost immediately move to in_progress.|\\n|`in_progress` | While in_progress, the Assistant uses the model and tools to perform steps. You can view progress being made by the Run by examining the Run Steps.|\\n|`completed` | The Run successfully completed! You can now view all Messages the Assistant added to the Thread, and all the steps the Run took. You can also continue the conversation by adding more user Messages to the Thread and creating another Run.|\\n|`requires_action` | When using the Function calling tool, the Run will move to a required_action state once the model determines the names and arguments of the functions to be called. You must then run those functions and submit the outputs before the run proceeds. If the outputs are not provided before the expires_at timestamp passes (roughly 10-mins past creation), the run will move to an expired status.|\\n|`expired` | This happens when the function calling outputs weren\\'t submitted before expires_at and the run expires. Additionally, if the runs take too long to execute and go beyond the time stated in expires_at, our systems will expire the run.|\\n|`cancelling`| You can attempt to cancel an in_progress run using the Cancel Run endpoint. Once the attempt to cancel succeeds, status of the Run moves to canceled. Cancelation is attempted but not guaranteed.|\\n|`cancelled` |Run was successfully canceled.|\\n|`failed` |You can view the reason for the failure by looking at the `last_error` object in the Run. The timestamp for the failure will be recorded under failed_at.|\\n\\n## Message annotations\\n\\nAssistant message annotations are different from the [content filtering annotations](../concepts/content-filter.md) that are present in completion and chat completion API responses. Assistant annotations can occur within the content array of the object. Annotations provide information around how you should annotate the text in the responses to the user.\\n\\nWhen annotations are present in the Message content array, you\\'ll see illegible model-generated substrings in the text that you need to replace with the correct annotations. These strings might look something like `【13†source】` or `sandbox:/mnt/data/file.csv`. Here’s a Python code snippet from OpenAI that replaces these strings with the information present in the annotations.\\n\\n```Python\\n\\nfrom openai import AzureOpenAI\\n    \\nclient = AzureOpenAI(\\n    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \\n    api_version=\"2024-02-15-preview\",\\n    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\\n    )\\n\\n# Retrieve the message object\\nmessage = client.beta.threads.messages.retrieve(\\n  thread_id=\"...\",\\n  message_id=\"...\"\\n)\\n\\n# Extract the message content\\nmessage_content = message.content[0].text\\nannotations = message_content.annotations\\ncitations = []\\n\\n# Iterate over the annotations and add footnotes\\nfor index, annotation in enumerate(annotations):\\n    # Replace the text with a footnote\\n    message_content.value = message_content.value.replace(annotation.text, f\\' [{index}]\\')\\n\\n    # Gather citations based on annotation attributes\\n    if (file_citation := getattr(annotation, \\'file_citation\\', None)):\\n        cited_file = client.files.retrieve(file_citation.file_id)\\n        citations.append(f\\'[{index}] {file_citation.quote} from {cited_file.filename}\\')\\n    elif (file_path := getattr(annotation, \\'file_path\\', None)):\\n        cited_file = client.files.retrieve(file_path.file_id)\\n        citations.append(f\\'[{index}] Click <here> to download {cited_file.filename}\\')\\n        # Note: File download functionality not implemented above for brevity\\n\\n# Add footnotes to the end of the message before displaying to user\\nmessage_content.value += \\'\\\\n\\' + \\'\\\\n\\'.join(citations)\\n\\n```\\n\\n|Message annotation | Description |\\n|---|---|\\n| `file_citation` | File citations are created by the retrieval tool and define references to a specific quote in a specific file that was uploaded and used by the Assistant to generate the response. |\\n|`file_path` | File path annotations are created by the code_interpreter tool and contain references to the files generated by the tool. |\\n\\n## See also\\n\\n* Learn more about Assistants and [Code Interpreter](./code-interpreter.md)\\n* Learn more about Assistants and [function calling](./assistant-functions.md)\\n* [Azure OpenAI Assistants API samples](https://github.com/Azure-Samples/azureai-samples/tree/main/scenarios/Assistants)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test chunking\n",
    "#row = df[df['file_name'] == 'use-your-data.md']\n",
    "row = df[df['file_name'] == 'assistant.md']\n",
    "# use list function to show all text in the cell\n",
    "md_content = list(row['content'])[0]\n",
    "md_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24cbbbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"H1\"),\n",
    "    (\"##\", \"H2\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(md_content)\n",
    "len(md_header_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e8a3087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 65\n",
      "1 476\n",
      "2 43\n",
      "3 215\n",
      "4 6348\n",
      "5 377\n",
      "6 516\n",
      "7 69\n"
     ]
    }
   ],
   "source": [
    "for j, md_split in enumerate(md_header_splits):\n",
    "    if 'H1' in md_split.metadata:\n",
    "        if 'H2' in md_split.metadata:\n",
    "            chunk = f\"## {md_split.metadata['H2']}\\n{md_split.page_content}\"\n",
    "        else:\n",
    "            chunk = f\"# {md_split.metadata['H1']}\\n{md_split.page_content}\"\n",
    "    else:\n",
    "        chunk = md_split.page_content\n",
    "    print(j, token_size(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5deaeac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Char-level splits\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=get_encoding_name(),\n",
    "    chunk_size=1200, \n",
    "    chunk_overlap=125\n",
    ")\n",
    "\n",
    "# Split\n",
    "splits = text_splitter.split_documents(md_header_splits)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea81b417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 65\n",
      "1 476\n",
      "2 43\n",
      "3 215\n",
      "4 312\n",
      "5 1183\n",
      "6 1167\n",
      "7 411\n",
      "8 1189\n",
      "9 280\n",
      "10 1107\n",
      "11 927\n",
      "12 109\n",
      "13 377\n",
      "14 516\n",
      "15 69\n"
     ]
    }
   ],
   "source": [
    "for j, md_split in enumerate(splits):\n",
    "    if 'H1' in md_split.metadata:\n",
    "        if 'H2' in md_split.metadata:\n",
    "            chunk = f\"## {md_split.metadata['H2']}\\n{md_split.page_content}\"\n",
    "        else:\n",
    "            chunk = f\"# {md_split.metadata['H1']}\\n{md_split.page_content}\"\n",
    "    else:\n",
    "        chunk = md_split.page_content\n",
    "    print(j, token_size(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd99903-5ce0-4ef3-aa1d-526b455ef37a",
   "metadata": {},
   "source": [
    "## MD Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40309d8c-2b55-4007-b5c6-65fe12f87f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>chunk</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>token_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to use content filters (preview) with Azur...</td>\n",
       "      <td># How to configure content filters with Azure ...</td>\n",
       "      <td>content-filters.md</td>\n",
       "      <td>0</td>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to use content filters (preview) with Azur...</td>\n",
       "      <td># How to configure content filters with Azure ...</td>\n",
       "      <td>content-filters.md</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to use content filters (preview) with Azur...</td>\n",
       "      <td>## Configuring content filters via Azure OpenA...</td>\n",
       "      <td>content-filters.md</td>\n",
       "      <td>2</td>\n",
       "      <td>958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to use content filters (preview) with Azur...</td>\n",
       "      <td>## Configuring content filters via Azure OpenA...</td>\n",
       "      <td>content-filters.md</td>\n",
       "      <td>3</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to use content filters (preview) with Azur...</td>\n",
       "      <td>## Best practices\\nWe recommend informing your...</td>\n",
       "      <td>content-filters.md</td>\n",
       "      <td>4</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>Use your image data with Azure OpenAI Service ...</td>\n",
       "      <td>## Additional Tips\\n### Adding and Removing Da...</td>\n",
       "      <td>use-your-image-data.md</td>\n",
       "      <td>8</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>Use your image data with Azure OpenAI Service ...</td>\n",
       "      <td>## Next steps\\n- You can also chat on Azure Op...</td>\n",
       "      <td>use-your-image-data.md</td>\n",
       "      <td>9</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>use-your-data-go.md</td>\n",
       "      <td>[!INCLUDE [Set up required variables](./use-yo...</td>\n",
       "      <td>use-your-data-go.md</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>use-your-data-go.md</td>\n",
       "      <td>1. Create a new folder named *openai-go* for y...</td>\n",
       "      <td>use-your-data-go.md</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>use-your-data-go.md</td>\n",
       "      <td>1. From the project directory, open the *sampl...</td>\n",
       "      <td>use-your-data-go.md</td>\n",
       "      <td>2</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1118 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     How to use content filters (preview) with Azur...   \n",
       "1     How to use content filters (preview) with Azur...   \n",
       "2     How to use content filters (preview) with Azur...   \n",
       "3     How to use content filters (preview) with Azur...   \n",
       "4     How to use content filters (preview) with Azur...   \n",
       "...                                                 ...   \n",
       "1113  Use your image data with Azure OpenAI Service ...   \n",
       "1114  Use your image data with Azure OpenAI Service ...   \n",
       "1115                                use-your-data-go.md   \n",
       "1116                                use-your-data-go.md   \n",
       "1117                                use-your-data-go.md   \n",
       "\n",
       "                                                  chunk  \\\n",
       "0     # How to configure content filters with Azure ...   \n",
       "1     # How to configure content filters with Azure ...   \n",
       "2     ## Configuring content filters via Azure OpenA...   \n",
       "3     ## Configuring content filters via Azure OpenA...   \n",
       "4     ## Best practices\\nWe recommend informing your...   \n",
       "...                                                 ...   \n",
       "1113  ## Additional Tips\\n### Adding and Removing Da...   \n",
       "1114  ## Next steps\\n- You can also chat on Azure Op...   \n",
       "1115  [!INCLUDE [Set up required variables](./use-yo...   \n",
       "1116  1. Create a new folder named *openai-go* for y...   \n",
       "1117  1. From the project directory, open the *sampl...   \n",
       "\n",
       "                   parent_id chunk_id token_size  \n",
       "0         content-filters.md        0        952  \n",
       "1         content-filters.md        1        276  \n",
       "2         content-filters.md        2        958  \n",
       "3         content-filters.md        3        506  \n",
       "4         content-filters.md        4        132  \n",
       "...                      ...      ...        ...  \n",
       "1113  use-your-image-data.md        8        201  \n",
       "1114  use-your-image-data.md        9        113  \n",
       "1115     use-your-data-go.md        0         18  \n",
       "1116     use-your-data-go.md        1        102  \n",
       "1117     use-your-data-go.md        2        943  \n",
       "\n",
       "[1118 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(md_content)\n",
    "len(md_header_splits)\n",
    "\n",
    "chunked_data = pd.DataFrame(columns=['title', 'chunk', 'parent_id', 'chunk_id', 'token_size'])\n",
    "\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "\n",
    "    md_content = row['content']\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "    md_header_splits = markdown_splitter.split_text(md_content)\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        encoding_name=get_encoding_name(),\n",
    "        chunk_size=1000, \n",
    "        chunk_overlap=125\n",
    "    )\n",
    "\n",
    "    # Split\n",
    "    splits = text_splitter.split_documents(md_header_splits)\n",
    "\n",
    "    for j, md_split in enumerate(splits):\n",
    "        try:\n",
    "            if 'H1' in md_split.metadata:\n",
    "                if 'H2' in md_split.metadata:\n",
    "                    chunk = f\"## {md_split.metadata['H2']}\\n{md_split.page_content}\"\n",
    "                else:\n",
    "                    chunk = f\"# {md_split.metadata['H1']}\\n{md_split.page_content}\"\n",
    "            else:\n",
    "                chunk = md_split.page_content\n",
    "            new_row = {'title':  row['title'], 'chunk': chunk, 'parent_id': row['file_name'], 'chunk_id': j, 'token_size': token_size(chunk)}\n",
    "            chunked_data = pd.concat([chunked_data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {i}, {j}, {e}\\n{md_split.metadata}\")\n",
    "\n",
    "\n",
    "chunked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c6d4e67-c635-4e62-bf82-ece30c5e5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # linear algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "371d32b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# chatgpt promt: \"python code to plot a graph group by count of bin size from data\"\n",
    "data = chunked_data['token_size']\n",
    "\n",
    "bin_size = 100\n",
    "\n",
    "# Calculate the number of bins based on the bin size\n",
    "num_bins = int(np.ceil((data.max() - data.min()) / bin_size))\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(data, bins=num_bins)\n",
    "\n",
    "# Set the axis labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Data')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc8cd4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file with token size > 2K\n",
    "len(chunked_data[chunked_data['token_size'] > 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ee66b-a9ea-4a32-9ee3-51e72cc8b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "#chunked_data.to_pickle('./aoai-docs_md.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
